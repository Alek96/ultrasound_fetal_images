# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: fetal_planes.yaml
  - override /model: fetal_module.yaml
  - override /callbacks: default.yaml
  - override /logger: many_loggers.yaml
  - override /trainer: gpu.yaml
#  - override /extras: plot_video_probabilities.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

find_lr: False

seed: "rand"

trainer:
  min_epochs: 0
  max_epochs: 40
  val_check_interval: 0.25
  accumulate_grad_batches: 1

callbacks:
  mix_up:
    alpha: 0.5
  #    softmax_target: False
  stochastic_weight_averaging:
    swa_lrs:
    swa_epoch_start:
  model_checkpoint:
    monitor: "val/acc"
    mode: "max"
  early_stopping:
    monitor: "val/acc"
    mode: "max"
    patience: 40
  class_image_sampler:
    class_names:
      - "Trans-thalamic"
      - "Trans-cerebellum"
      - "Trans-ventricular"
      - "Other"
      - "Not A Brain"

model:
  criterion:
    label_smoothing: 0.02
  optimizer:
    lr: 5e-04
    weight_decay: 1e-05
  #  scheduler:
  #    factor: 0.5
  #    patience: 5
  net_spec:
    name: "efficientnet_v2_m"

data:
  input_size: [165, 240]
  train_val_split: 0.2
  train_val_split_seed: 5724
  batch_size: 32
  num_workers: 8
  pin_memory: True
  sampler: "under"
  train_transforms:
    - _target_: torchvision.transforms.Grayscale
    - _target_: torchvision.transforms.Resize
      size: ${data.input_size}
      antialias: true

    #- _target_: torchvision.transforms.AutoAugment
    #  policy:
    #    _target_: src.utils.utils.import_object
    #    name: torchvision.transforms.AutoAugmentPolicy.IMAGENET
    #- _target_: torchvision.transforms.RandAugment
    #  magnitude: 11
    - _target_: src.data.components.transforms.RandAugment
      policy:
        _target_: src.utils.utils.import_object
        name: src.data.components.transforms.RandAugmentPolicy.RAND_AUGMENT_CUTOUT
      num_ops: 2
      magnitude: 11
      arg1: 0.7
      arg2: 5
    #- _target_: torchvision.transforms.TrivialAugmentWide
    #- _target_: torchvision.transforms.AugMix

    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    #- _target_: torchvision.transforms.RandomVerticalFlip
    #  p: 0.5

    #- _target_: torchvision.transforms.RandomAffine
    #  degrees: 30
    #  translate: [ 0.1, 0.1 ]
    #  scale: [ 1.0, 1.2 ]

    - _target_: torchvision.transforms.ConvertImageDtype
      dtype:
        _target_: src.utils.utils.import_object
        name: torch.float32

    #- _target_: torchvision.transforms.Normalize  # FetalBrain
    #  mean: 0.17
    #  std: 0.19
    #- _target_: torchvision.transforms.Normalize  # ImageNet
    #  mean: 0.449
    #  std: 0.226

logger:
  wandb:
    project: "brain_planes"
    tags: ${tags}
    group: "brain_planes"
#extras:
#  after_test_plots:
#    enabled: true
#    data_dir: ${paths.data_dir}
#    video_dataset_dir: "US_VIDEOS_0.3"
#    batch_size: ${data.batch_size}
#    input_size: ${data.input_size}
#    min_probabilities:
#      [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995]
#    probability_norm: 1.0
