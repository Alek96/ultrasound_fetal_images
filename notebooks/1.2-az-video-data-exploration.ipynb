{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchvision.io import read_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('png')\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import (\n",
    "    FetalBrainPlanesDataset,\n",
    "    USVideosDataset,\n",
    "    USVideosFrameDataset,\n",
    "    VideoQualityDataset,\n",
    ")\n",
    "from src.data.components.transforms import Affine, HorizontalFlip\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "from src.models.quality_module import QualityLitModule\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS_tran_250_playful-haze-2111\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(path / \"selected\", ignore_errors=True)\n",
    "# shutil.rmtree(path / \"labeled\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_14-32-35\" / \"4\"\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_video(video_path: Path):\n",
    "    video_dense = []\n",
    "    video_logits = []\n",
    "    video_y_hats = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    for frame in _frame_iter(vidcap, \"Label frames\"):\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frame = frame.to(model.device)\n",
    "\n",
    "        batch_size = 128\n",
    "        batches = ceil(len(transforms) / batch_size)\n",
    "        batch_dense = []\n",
    "        batch_logits = []\n",
    "        batch_y_hats = []\n",
    "        for i in range(batches):\n",
    "            batch_transforms = transforms[i * batch_size : (i + 1) * batch_size]\n",
    "            frames = torch.stack([transform(frame) for transform in batch_transforms])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                dense, logits = model(frames)\n",
    "                y_hats = F.softmax(logits, dim=1)\n",
    "\n",
    "            batch_dense.append(dense.cpu())\n",
    "            batch_logits.append(logits.cpu())\n",
    "            batch_y_hats.append(y_hats.cpu())\n",
    "\n",
    "        video_dense.append(torch.cat(batch_dense, dim=0))\n",
    "        video_logits.append(torch.cat(batch_logits, dim=0))\n",
    "        video_y_hats.append(torch.cat(batch_y_hats, dim=0))\n",
    "\n",
    "    return torch.stack(video_dense, dim=1), torch.stack(video_logits, dim=1), torch.stack(video_y_hats, dim=1)\n",
    "\n",
    "\n",
    "def _frame_iter(capture, description):\n",
    "    def iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "\n",
    "    return tqdm(\n",
    "        iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def lable_transform_video(video_path, horizontal_flips, rotate_degrees, translates, scales):\n",
    "    global transforms\n",
    "\n",
    "    transforms = [\n",
    "        T.Compose(\n",
    "            [\n",
    "                T.Grayscale(),\n",
    "                T.Resize((165, 240), antialias=False),\n",
    "                HorizontalFlip(flip=horizontal_flip),\n",
    "                Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "                T.ConvertImageDtype(torch.float32),\n",
    "            ]\n",
    "        )\n",
    "        for horizontal_flip, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips, rotate_degrees, translates, scales\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return label_video(video_path)\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((path / \"videos\" / \"test\").iterdir())[0]\n",
    "\n",
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "\n",
    "# _, logits, y_hats = lable_transform_video(\n",
    "#     video_path=video_path,\n",
    "#     horizontal_flips=[False, True],\n",
    "#     rotate_degrees=[0, -15, 15],\n",
    "#     translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "#     scales=[1.0, 1.2],\n",
    "# )\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(y_hats, ax):\n",
    "    x = list(range(y_hats.shape[0]))\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x, y_hats[:, i], label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_best_probabilities(y_hats, ax):\n",
    "    x = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        x[best].append(i)\n",
    "        y[best].append(y_hat[best])\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=1, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def is_stable(y, i):\n",
    "    min_i = max(0, i - window)\n",
    "    max_i = min(i + window, len(y) - 1)\n",
    "\n",
    "    if min_i > i - window or max_i < i + window:\n",
    "        return False\n",
    "\n",
    "    for j in range(min_i, max_i + 1):\n",
    "        if y[j] == 0.0:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def plot_filtered_probabilities(y_hats, ax):\n",
    "    x = torch.arange(0, y_hats.shape[0]).int().repeat(y_hats.shape[1], 1).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], y_hats.shape[0])).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        y[best][i] = y_hat[best]\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        to_delete = []\n",
    "\n",
    "        for j in range(len(y[i])):\n",
    "            if not is_stable(y[i], j):\n",
    "                to_delete.append(j)\n",
    "\n",
    "        to_delete.sort(reverse=True)\n",
    "        for j in to_delete:\n",
    "            x[i].pop(j)\n",
    "            y[i].pop(j)\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=1, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_base_probabilities(y_hats):\n",
    "    ncols = 3\n",
    "    nrows = len(y_hats)\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=ncols,\n",
    "        nrows=nrows,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False,\n",
    "        tight_layout=True,\n",
    "        figsize=(10 * ncols, 5 * nrows),\n",
    "    )\n",
    "\n",
    "    for i in range(nrows):\n",
    "        plot_probabilities(y_hats[i], axes[i, 0])\n",
    "        plot_best_probabilities(y_hats[i], axes[i, 1])\n",
    "        plot_filtered_probabilities(y_hats[i], axes[i, 2])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax[0].set_xlim(left=0, right=y_hats.shape[1])\n",
    "        ax[0].set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "plot_base_probabilities(y_hats_[:1])\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_probabilities(y_hats[0], axes)\n",
    "# # plot_best_probabilities(y_hats[0], axes)\n",
    "# plot_filtered_probabilities(y_hats[0], axes)\n",
    "# axes.set_xlim(left=0, right=y_hats.shape[1])\n",
    "# axes.set_ylim(bottom=0, top=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of quality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [2.0, 3.0, 4.0], [3.0, 4.0, 5.0], [1.0, 3.0, 2.0], [1.0, 3.0, 2.0]],\n",
    "        [[1.0, 4.0, 2.0], [2.0, 4.0, 3.0], [3.0, 4.0, 6.0], [1.0, 4.0, 2.0], [1.0, 5.0, 2.0]],\n",
    "    ]\n",
    ")\n",
    "print(y_hats_.shape)\n",
    "\n",
    "pred = torch.argmax(y_hats_, dim=2)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "\n",
    "y_hats_ = y_hats_ * F.one_hot(pred)\n",
    "# mask = F.one_hot(pred) == 0\n",
    "# y_hats_ = torch.masked_fill(y_hats_, mask, 0.0)\n",
    "\n",
    "print(y_hats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        min_j = max(0, j - window)\n",
    "        max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "        if not torch.all(pred[i, min_j:max_j] == pred[i, j]):\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        if torch.sum(pred[i, j - window : j + window + 1] == pred[i, j]) < 1 + 2 * window:\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats__ = torch.mean(y_hats_, dim=0)\n",
    "print(y_hats__.shape)\n",
    "print(y_hats__)\n",
    "\n",
    "plates = y_hats__[:, :2]\n",
    "other = y_hats__[:, 2:]\n",
    "\n",
    "quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "print(quality)\n",
    "\n",
    "quality = quality / torch.sum(plates > 0, dim=1)\n",
    "zaro_mask = torch.eq(quality > 0, False)\n",
    "torch.masked_fill(quality, zaro_mask, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate quality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality(y_hats: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=1, nrows=3, tight_layout=True, figsize=(10, 15))\n",
    "\n",
    "    plot_mean_filtered_probabilities(y_hats, axes[0])\n",
    "    plot_quality_dots(quality, axes[1])\n",
    "    plot_quality_line(quality, axes[2])\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_mean_filtered_probabilities(y_hats: Tensor, ax):\n",
    "    for i, label in enumerate(label_def):\n",
    "        x, y = extract_nonzero_values(y_hats[:, i])\n",
    "        ax.plot(x, y, \"o\", markersize=1, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(y_hats))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def plot_quality_dots(quality: Tensor, ax):\n",
    "    ax.plot(range(len(quality)), quality, \"o\", markersize=2, color=\"tab:gray\")\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(quality))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def plot_quality_line(quality: Tensor, ax):\n",
    "    ax.plot(range(len(quality)), quality, color=\"tab:gray\")\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(quality))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def extract_nonzero_values(y_hats):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        if y_hat > 0:\n",
    "            x.append(i)\n",
    "            y.append(y_hat)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)  # ???\n",
    "\n",
    "    # (sum planes' prediction - sum no planes' prediction) / (number of planes' prediction greater than 0)\n",
    "    plates = y_hats[:, :3]\n",
    "    other = y_hats[:, 3:]\n",
    "    quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "    quality = quality / torch.sum(plates > 0, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "# plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# plot_quality_line(quality, axes)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logits(data_path: Path):\n",
    "    dense = []\n",
    "    for video_path in sorted(data_path.iterdir()):\n",
    "        path = sorted(video_path.iterdir())[0]\n",
    "        logits, _, _ = torch.load(path)\n",
    "        dense.append(logits)\n",
    "    return torch.cat(dense)\n",
    "\n",
    "\n",
    "def save_std_mean(data_path: Path, logits):\n",
    "    std_mean = torch.std_mean(logits, unbiased=False, dim=0)\n",
    "    torch.save(std_mean, f\"{data_path}/std_mean.pt\")\n",
    "    print(std_mean[0].shape)\n",
    "\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS_tran_\" / \"data\"\n",
    "dense = load_logits(path / \"train\")\n",
    "save_std_mean(path, dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transfor operation to quality plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((path / \"videos\" / \"test\").iterdir())[0]\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality(y_hats: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, tight_layout=True, figsize=(20, 5))\n",
    "\n",
    "    plot_mean_filtered_probabilities(y_hats_, axes[0])\n",
    "    plot_quality_line(quality, axes[1])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    rotate_degrees=[0, -15, 15],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0, 1.1, 1.2],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    rotate_degrees=[0, -15, 15],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.2],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of quality plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Class probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_1_class_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_best_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Highest probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_2_highest_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_filtered_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Stable probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_3_stable_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_mean_filtered_probabilities(y_hats_, ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Mean probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_4_mean_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "ax.plot(range(len(quality)), quality, color=\"tab:cyan\")\n",
    "\n",
    "ax.set_xlim(left=0, right=len(quality))\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality\", size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_5_frame_quality.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate frames quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (165, 240)\n",
    "\n",
    "videos = USVideosFrameDataset(\n",
    "    data_dir=str(root / \"data\"),\n",
    "    dataset_name=\"US_VIDEOS_tran_250_playful-haze-2111\",\n",
    "    train=False,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize(img_size, antialias=True),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "samples = 5\n",
    "beans = 10\n",
    "\n",
    "nrows = 1\n",
    "figsize = 1.5\n",
    "scale = img_size[0] / img_size[1]\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=nrows,\n",
    "    squeeze=True,\n",
    "    tight_layout=True,\n",
    "    figsize=(figsize * samples, figsize * scale * nrows * 3),\n",
    "    #     figsize=(7, 3)\n",
    "    #     dpi=600,\n",
    ")\n",
    "\n",
    "\n",
    "min_quality = 0.3\n",
    "y_hat = quality\n",
    "preds = torch.argmax(y_hats[0], dim=1)\n",
    "qualities = []\n",
    "\n",
    "rows = []\n",
    "# For each label\n",
    "for j in range(3):\n",
    "    mask = torch.ne(preds, j)\n",
    "    y_hat_label = torch.masked_fill(y_hat, mask, 0)\n",
    "    # y_hat_label[:25] = 0  # omit first 25 frames\n",
    "    best = torch.argsort(y_hat_label, descending=True)\n",
    "\n",
    "    # delete frames from other classes and low quality frames\n",
    "    best = [idx.item() for idx in best if y_hat_label[idx] != 0 and y_hat_label[idx] > min_quality]\n",
    "\n",
    "    bean_size = int(len(best) / beans) + 1\n",
    "    samples_ = [idx for i, idx in enumerate(best) if i % bean_size == 0][:samples]\n",
    "\n",
    "    # for each sample\n",
    "    frames = [videos[0, idx] for idx in reversed(samples_)]\n",
    "    row = torch.cat(frames, dim=2)\n",
    "    rows.append(row)\n",
    "\n",
    "    qualities.extend([y_hat[idx].item() for idx in reversed(samples_)])\n",
    "\n",
    "img = torch.cat(rows, dim=1)\n",
    "img = TF.to_pil_image(img)\n",
    "img = TF.to_grayscale(img)\n",
    "img = np.asarray(img)\n",
    "axes.imshow(img, cmap=\"gray\")\n",
    "axes.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "for col_idx in range(samples):\n",
    "    for label_idx in range(3):\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 10,\n",
    "            round(qualities[label_idx * samples + col_idx], 2),\n",
    "            size=\"large\",\n",
    "            color=\"tab:cyan\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "\n",
    "for label_idx in range(3):\n",
    "    axes.text(\n",
    "        -30,\n",
    "        img_size[0] * label_idx + img_size[0] / 2,\n",
    "        label_def[label_idx].replace(\"-\", \"\\n\"),\n",
    "        rotation=90,\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Standard Planes\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/samples_planes.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_durations_statistics(path: Path):\n",
    "    videos_path = path / \"videos\"\n",
    "    durations = torch.cat(\n",
    "        [\n",
    "            video_durations(videos_path / \"train\"),\n",
    "            video_durations(videos_path / \"test\"),\n",
    "        ]\n",
    "    )\n",
    "    return durations.min(), durations.max(), torch.std_mean(durations)\n",
    "\n",
    "\n",
    "def video_durations(videos_path: Path):\n",
    "    durations = []\n",
    "    videos = sorted(videos_path.iterdir())\n",
    "    for video_path in tqdm(videos, desc=\"cound duration videos\"):\n",
    "        durations.append(video_duration(video_path))\n",
    "\n",
    "    return torch.tensor(durations)\n",
    "\n",
    "\n",
    "def video_duration(video_path: Path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count / fps\n",
    "\n",
    "\n",
    "min_duration, max_duration, (std_duration, mean_duration) = video_durations_statistics(path)\n",
    "\n",
    "print(\"Duration\")\n",
    "print(f\"min {min_duration}\")\n",
    "print(f\"max {max_duration}\")\n",
    "print(f\"std {std_duration}\")\n",
    "print(f\"mean {mean_duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-06-23_03-33-10\"  # drawn-deluge-559\n",
    "checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-06-25_20-03-39\"  # logical-sun-1331\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "rnn = QualityLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "rnn.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoQualityDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_tran_250_playful-haze-2111\",\n",
    "    train=False,\n",
    "    seq_len=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn(i):\n",
    "    x, y, preds = dataset[i]\n",
    "    x = x.to(device=rnn.device)\n",
    "    y = y.to(device=rnn.device)\n",
    "    with torch.no_grad():\n",
    "        y_hat = rnn(x.unsqueeze(0)).squeeze()\n",
    "    return y.cpu(), y_hat.cpu(), preds\n",
    "\n",
    "\n",
    "y, y_hat, preds = test_rnn(0)\n",
    "\n",
    "\n",
    "label_def = FetalBrainPlanesDataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3), dpi=300)\n",
    "\n",
    "x = list(range(len(y)))\n",
    "ax.plot(x, y, label=\"true\", color=\"tab:gray\")\n",
    "ax.plot(x, y_hat, label=\"predicted\", color=\"tab:cyan\")\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality\", size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_frame_quality_to_true_frame_quality.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3), dpi=300)\n",
    "\n",
    "plot_best_probabilities(y_hats[0], ax)\n",
    "\n",
    "\n",
    "x = list(range(len(y)))\n",
    "ax.plot(x, y_hat, label=\"predicted\", color=\"tab:cyan\")\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality \\\\ probability\".replace(\"_\", \"\\n\"), size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "ax.legend(fontsize=\"x-small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_frame_quality_to_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (165, 240)\n",
    "\n",
    "videos = USVideosFrameDataset(\n",
    "    data_dir=str(root / \"data\"),\n",
    "    dataset_name=\"US_VIDEOS_tran_250_playful-haze-2111\",\n",
    "    train=False,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize(img_size, antialias=True),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "min_quality = 0.3\n",
    "samples = 5\n",
    "beans = 10\n",
    "\n",
    "nrows = 1\n",
    "figsize = 1.5\n",
    "scale = img_size[0] / img_size[1]\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=nrows,\n",
    "    squeeze=True,\n",
    "    tight_layout=True,\n",
    "    figsize=(figsize * samples, figsize * scale * nrows * 3),\n",
    "    #     figsize=(7, 3)\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "\n",
    "qualities = []\n",
    "true_qualities = []\n",
    "\n",
    "rows = []\n",
    "# For each label\n",
    "for j in range(3):\n",
    "    mask = torch.ne(preds, j)\n",
    "    y_hat_label = torch.masked_fill(y_hat, mask, 0)\n",
    "    # y_hat_label[:25] = 0  # omit first 25 frames\n",
    "    best = torch.argsort(y_hat_label, descending=True)\n",
    "\n",
    "    # delete frames from other classes and low quality frames\n",
    "    best = [idx.item() for idx in best if y_hat_label[idx] != 0 and y_hat_label[idx] > min_quality]\n",
    "\n",
    "    bean_size = int(len(best) / beans) + 1\n",
    "    samples_ = [idx for i, idx in enumerate(best) if i % bean_size == 0][:samples]\n",
    "\n",
    "    # for each sample\n",
    "    frames = [videos[0, idx] for idx in reversed(samples_)]\n",
    "    row = torch.cat(frames, dim=2)\n",
    "    rows.append(row)\n",
    "\n",
    "    qualities.extend([y_hat[idx].item() for idx in reversed(samples_)])\n",
    "    true_qualities.extend([y[idx].item() for idx in reversed(samples_)])\n",
    "\n",
    "img = torch.cat(rows, dim=1)\n",
    "img = TF.to_pil_image(img)\n",
    "img = TF.to_grayscale(img)\n",
    "img = np.asarray(img)\n",
    "axes.imshow(img, cmap=\"gray\")\n",
    "axes.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "for col_idx in range(samples):\n",
    "    for label_idx in range(3):\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 10,\n",
    "            f\"{qualities[label_idx * samples + col_idx]:.2f}\",\n",
    "            size=\"large\",\n",
    "            color=\"tab:cyan\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 41,\n",
    "            f\"{true_qualities[label_idx * samples + col_idx]:.2f}\",\n",
    "            size=\"large\",\n",
    "            color=\"tab:gray\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "\n",
    "for label_idx in range(3):\n",
    "    axes.text(\n",
    "        -30,\n",
    "        img_size[0] * label_idx + img_size[0] / 2,\n",
    "        label_def[label_idx].replace(\"-\", \"\\n\"),\n",
    "        rotation=90,\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Standard Planes\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_samples_planes.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
