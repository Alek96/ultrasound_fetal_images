{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from collections.abc import Sequence\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from typing import Callable, Iterator, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from ipywidgets import Video\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('png')\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import (\n",
    "    FetalBrainPlanesDataset,\n",
    "    USVideosDataset,\n",
    "    USVideosFrameDataset,\n",
    "    USVideosSsimFrameDataset,\n",
    "    VideoQualityDataset,\n",
    "    VideosFrameDataset,\n",
    "    batch_tensor,\n",
    ")\n",
    "from src.data.components.samplers import UnderSampler\n",
    "from src.data.components.transforms import (\n",
    "    Affine,\n",
    "    HorizontalFlip,\n",
    "    LabelEncoder,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "from src.models.quality_module import QualityLitModule\n",
    "\n",
    "videos_path = root / \"data\" / \"US_VIDEOS\"\n",
    "path = root / \"data\" / \"US_VIDEOS_tran_0500\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-07_21-10-40\" / \"0\"  # frosty-forest-2691\n",
    "\n",
    "checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_22-41-24\"  # civilized-droid-3054\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-05_09-31-12\"  # carbonite-ewok-3069\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_14-12-45\"  # tusken-transport-3040\n",
    "\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-26_07-45-41\"  # neat-aardvark-2941\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_03-38-18\"  # fine-lion-2828\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_13-37-18\"  # fresh-grass-2813\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-23_18-16-01\"  # prime-butterfly-2873\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-24_12-02-44\"  # lilac-frost-2893\n",
    "\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_21-48-38\"  # glowing-sea-2849 highest tta_acc\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_19-18-09\"  # swift-butterfly-2819 highest f1\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-20_07-04-24\"  # sunny-flower-2780 lowest loss\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Similarity (SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SSIM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = USVideosFrameDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS\",\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "frames = []\n",
    "for video in videos:\n",
    "    for i, frame in enumerate(video):\n",
    "        frames.append((frame, str(i)))\n",
    "        if len(frames) == 9:\n",
    "            break\n",
    "    if len(frames) == 9:\n",
    "        break\n",
    "\n",
    "show_pytorch_images(frames)\n",
    "\"frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ssim_frames(video: VideosFrameDataset, ssim_max: float):\n",
    "    frames = []\n",
    "    img = None\n",
    "    for i, frame in enumerate(tqdm(video, desc=\"Video\", leave=False)):\n",
    "        frame_np = frame.numpy()[0]\n",
    "        if img is None or structural_similarity(img, frame_np, data_range=frame_np.max() - frame_np.min()) <= ssim_max:\n",
    "            frames.append((frame, i))\n",
    "            img = frame_np\n",
    "        break\n",
    "    return frames\n",
    "\n",
    "\n",
    "def select_ssim_videos(videos: USVideosFrameDataset, ssim_dataset_path, ssim_max):\n",
    "    if not ssim_dataset_path.is_dir():\n",
    "        ssim_dataset_path.mkdir(parents=True)\n",
    "\n",
    "    ssim_images_path = ssim_dataset_path / \"images\"\n",
    "    shutil.rmtree(ssim_images_path, ignore_errors=True)\n",
    "\n",
    "    for video in tqdm(videos, desc=\"Videos\"):\n",
    "        ssim_frames_path = ssim_images_path / video.video_path.stem\n",
    "        ssim_frames_path.mkdir(parents=True)\n",
    "        frames = select_ssim_frames(video, ssim_max)\n",
    "        for frame, frame_idx in frames:\n",
    "            frame_path = ssim_frames_path / f\"frame_{frame_idx:06d}.jpg\"\n",
    "            save_image(frame, str(frame_path))\n",
    "\n",
    "\n",
    "# show first video\n",
    "# frames = select_ssim_frames(videos[0], 0.6)\n",
    "# show_pytorch_images(frames[:9])\n",
    "# \"ssim frames\"\n",
    "\n",
    "select_ssim_videos(videos=videos, ssim_dataset_path=root / \"data\" / \"US_VIDEOS_ssim_0.6\", ssim_max=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ssim_csv(ssim_dataset: USVideosSsimFrameDataset, batch_size: int = 1, tta: bool = False):\n",
    "    with open(f\"{ssim_dataset.dataset_dir}/data.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Video_idx\", \"Video_name\", \"Frame_idx\", \"Class_idx\", \"Class_name\", \"Probability\"])\n",
    "\n",
    "        for video_idx, video in enumerate(tqdm(ssim_dataset, desc=\"Videos\")):\n",
    "            for batch_idx, frames in enumerate(batch_tensor(video, batch_size)):\n",
    "                frames = frames.to(model.device)\n",
    "\n",
    "                if not tta:\n",
    "                    with torch.no_grad():\n",
    "                        _, logits = model.forward(frames)\n",
    "                        y_hats = F.softmax(logits, dim=1)\n",
    "                        preds = torch.argmax(y_hats, dim=1)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        _, y_hats = model.forward_tta(frames)\n",
    "                        preds = torch.argmax(y_hats, dim=1)\n",
    "\n",
    "                for frame_idx, (y_hat, pred) in enumerate(zip(y_hats, preds)):\n",
    "                    writer.writerow(\n",
    "                        [\n",
    "                            video_idx,\n",
    "                            video.video_path.stem,\n",
    "                            batch_size * batch_idx + frame_idx,\n",
    "                            pred.item(),\n",
    "                            FetalBrainPlanesDataset.labels[pred],\n",
    "                            y_hat[pred].item(),\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "\n",
    "ssim_dataset = USVideosSsimFrameDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_ssim_0.7\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "# model.to(\"cuda\")\n",
    "\n",
    "create_ssim_csv(ssim_dataset, batch_size=32, tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_log_dir: Path, tta_transforms: dict = None):\n",
    "    checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "    model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "    # disable randomness, dropout, etc...\n",
    "    model.eval()\n",
    "\n",
    "    if tta_transforms is not None:\n",
    "        model.tta_transforms = FetalLitModule.create_transforms(tta_transforms)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tta_transforms = {\n",
    "    \"horizontal_flips\": [False, True],\n",
    "    \"vertical_flips\": [False, True],\n",
    "    \"rotate_degrees\": [0, -5, 5],\n",
    "    \"translates\": [[0.0, 0.0]],\n",
    "    \"scales\": [1.0, 1.10],\n",
    "}\n",
    "\n",
    "models = [\n",
    "    load_model(model_log_dir, tta_transforms)\n",
    "    for model_log_dir in [\n",
    "        # seed 5724\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_22-41-24\",  # civilized-droid-3054\n",
    "        # root / \"logs\" / \"train\" / \"runs\" / \"2025-05-05_09-31-12\",  # carbonite-ewok-3069\n",
    "        # root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_14-12-45\",  # tusken-transport-3040\n",
    "        # seed 8910,\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-19_00-12-17\",  # dainty-totem-3234\n",
    "        # seed 9759\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-19_11-58-46\",  # lunar-grass-3253\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "def create_ssim_csv_multimodels(ssim_dataset: USVideosSsimFrameDataset, batch_size: int = 1):\n",
    "    with open(f\"{ssim_dataset.dataset_dir}/data.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Video_idx\", \"Video_name\", \"Frame_idx\", \"Class_idx\", \"Class_name\", \"Probability\"])\n",
    "\n",
    "        for video_idx, video in enumerate(tqdm(ssim_dataset, desc=\"Videos\")):\n",
    "            for batch_idx, frames in enumerate(batch_tensor(video, batch_size)):\n",
    "\n",
    "                y_hat_models = []\n",
    "                for model in models:\n",
    "                    frames = frames.to(model.device)\n",
    "                    with torch.no_grad():\n",
    "                        _, y_hats = model.forward_tta(frames)\n",
    "                    y_hat_models.append(y_hats)\n",
    "\n",
    "                y_hats = torch.mean(torch.stack(y_hat_models, dim=1), dim=1)\n",
    "                preds = torch.argmax(y_hats, dim=1)\n",
    "\n",
    "                for frame_idx, (y_hat, pred) in enumerate(zip(y_hats, preds)):\n",
    "                    writer.writerow(\n",
    "                        [\n",
    "                            video_idx,\n",
    "                            video.video_path.stem,\n",
    "                            batch_size * batch_idx + frame_idx,\n",
    "                            pred.item(),\n",
    "                            FetalBrainPlanesDataset.labels[pred],\n",
    "                            y_hat[pred].item(),\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "\n",
    "ssim_dataset = USVideosSsimFrameDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_ssim_0.6\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "# model.to(\"cuda\")\n",
    "\n",
    "create_ssim_csv_multimodels(ssim_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore SSIM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = pd.read_csv(f\"{root / \"data\" / \"US_VIDEOS_ssim_0.6\"}/data.csv\")\n",
    "img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels_2 = img_labels[img_labels[\"Probability\"] > 0.7].reset_index(drop=True)\n",
    "\n",
    "brain_plane = img_labels_2[\"Class_name\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "\n",
    "classes = np.unique(brain_plane)\n",
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=classes, y=brain_plane)\n",
    "\n",
    "pd.DataFrame({\"Count\": counts[classes], \"Weight\": class_weight})\n",
    "\n",
    "# 0.7 -> 642 (0.0), 144\t(0.7), 64 (0.8)\n",
    "# 0.6 -> 271 (0.0), 58\t(0.7), 28 (0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_dataset = USVideosSsimFrameDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_ssim_0.6\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "frames = []\n",
    "for index, row in img_labels.iterrows():\n",
    "    video_idx = row[\"Video_idx\"]\n",
    "    frame_idx = row[\"Frame_idx\"]\n",
    "    class_idx = row[\"Class_idx\"]\n",
    "    prop = row[\"Probability\"]\n",
    "    if class_idx == 3 and prop > 0.7:\n",
    "        frame = ssim_dataset[video_idx, frame_idx]\n",
    "        frames.append((frame, f\"{prop:.2f}\"))\n",
    "        if len(frames) == 25:\n",
    "            break\n",
    "\n",
    "if len(frames) > 0:\n",
    "    _ = show_pytorch_images(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SsimFrameDataset(Dataset):\n",
    "    labels = FetalBrainPlanesDataset.labels\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        dataset_name: str = \"FETAL_PLANES\",\n",
    "        min_probpabilities: float = [0.8, 0.8, 0.8, 0.8, 0.8],\n",
    "        transform: Callable | None = None,\n",
    "        target_transform: Callable | None = None,\n",
    "    ):\n",
    "        self.dataset_dir = f\"{data_dir}/{dataset_name}\"\n",
    "        self.img_labels = self.load_img_labels(min_probpabilities)\n",
    "        self.ssim_dataset = USVideosSsimFrameDataset(\n",
    "            data_dir=data_dir,\n",
    "            dataset_name=dataset_name,\n",
    "            transform=transform,\n",
    "        )\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def load_img_labels(self, min_probpabilities: list[float]):\n",
    "        img_labels = pd.read_csv(f\"{self.dataset_dir}/data.csv\")\n",
    "        idxs = None\n",
    "        for class_idx, min_prob in enumerate(min_probpabilities):\n",
    "            if idxs is None:\n",
    "                idxs = (img_labels[\"Class_idx\"] == class_idx) & (img_labels[\"Probability\"] > min_prob)\n",
    "            else:\n",
    "                idxs = idxs | ((img_labels[\"Class_idx\"] == class_idx) & (img_labels[\"Probability\"] > min_prob))\n",
    "\n",
    "        img_labels = img_labels[idxs]\n",
    "        return img_labels.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            idx, sub_idx = idx\n",
    "            if sub_idx == 0:\n",
    "                return self.get_image(idx)\n",
    "            elif sub_idx == 1:\n",
    "                return self.get_label(idx)\n",
    "\n",
    "        return self.get_image(idx), self.get_label(idx)\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "\n",
    "        video_idx = self.img_labels.Video_idx[idx]\n",
    "        frame_idx = self.img_labels.Frame_idx[idx]\n",
    "        return self.ssim_dataset[video_idx, frame_idx]\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "\n",
    "        label = self.img_labels.Class_name[idx]\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return label\n",
    "\n",
    "\n",
    "def get_under_sampler_config(\n",
    "    dataset: Dataset,\n",
    "    labels: torch.Tensor,\n",
    "    max_sizes: Sequence[int],\n",
    ") -> tuple[Sequence[torch.Tensor], Sequence[int]]:\n",
    "    classes = torch.tensor([dataset[i, 1].item() for i in range(len(dataset))])\n",
    "    classes_indices = [torch.nonzero(classes == class_id).flatten() for class_id in torch.unique(labels)]\n",
    "    classes_num_samples = [len(indices) for indices in classes_indices]\n",
    "\n",
    "    print(f\"dataset: {len(dataset)}, classes_num_samples: {classes_num_samples}\")\n",
    "\n",
    "    for i, max_size in enumerate(max_sizes):\n",
    "        if max_size >= 0:\n",
    "            classes_num_samples[i] = min(classes_num_samples[i], max_size)\n",
    "\n",
    "    return classes_indices, classes_num_samples\n",
    "\n",
    "\n",
    "def get_under_sampler(\n",
    "    datasets: Sequence[Dataset], labels: torch.Tensor, max_sizes: Sequence[Sequence[int]]\n",
    ") -> UnderSampler:\n",
    "    # log.info(\"Instantiating UnderSampler\")\n",
    "    classes_index = 0\n",
    "    classes_indices = []\n",
    "    classes_num_samples = []\n",
    "    for dataset, max_size in zip(datasets, max_sizes):\n",
    "        dataset_classes_indices, dataset_classes_num_samples = get_under_sampler_config(dataset, labels, max_size)\n",
    "        dataset_classes_indices = [[j + classes_index for j in i] for i in dataset_classes_indices]\n",
    "\n",
    "        classes_indices.extend(dataset_classes_indices)\n",
    "        classes_num_samples.extend(dataset_classes_num_samples)\n",
    "        classes_index += len(dataset)\n",
    "\n",
    "    m = 0\n",
    "    for i in classes_indices:\n",
    "        for j in i:\n",
    "            m = max(m, j)\n",
    "    print(f\"max idx: {m}\")\n",
    "\n",
    "    return UnderSampler(\n",
    "        classes_indices=classes_indices,\n",
    "        classes_num_samples=classes_num_samples,\n",
    "    )\n",
    "\n",
    "\n",
    "ssim_dataset = SsimFrameDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_ssim_0.7\",\n",
    "    min_probpabilities=[0.9, 0.9, 0.9, 0.5, 0.9],\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(\n",
    "        labels=FetalBrainPlanesDataset.labels,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "planes_dataset = FetalBrainPlanesDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    subset=\"train\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(\n",
    "        labels=FetalBrainPlanesDataset.labels,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset=ConcatDataset([planes_dataset, ssim_dataset]),\n",
    "    batch_size=9,\n",
    "    sampler=get_under_sampler(\n",
    "        [planes_dataset, ssim_dataset],\n",
    "        labels=torch.arange(5),\n",
    "        max_sizes=[[-1, -1, -1, -1, 500], [100, 100, 100, 100, 0]],\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"data_loader: {len(data_loader)}\")\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    x, y = batch\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    show_pytorch_images(torch.unbind(x, dim=0))\n",
    "    break\n",
    "\n",
    "# frames = []\n",
    "# for i in range(1000):\n",
    "#     class_idx = ssim_dataset[i, 1]\n",
    "#     if class_idx == \"Other\":\n",
    "#         frame = ssim_dataset[i, 0]\n",
    "#         frames.append((frame, f\"{prop:.2f}\"))\n",
    "#         if len(frames) == 25:\n",
    "#             break\n",
    "\n",
    "# if len(frames) > 0:\n",
    "#     _ = show_pytorch_images(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "# device = \"cuda\"\n",
    "# model.to(device)\n",
    "# video_path = sorted((path / \"videos\" / \"test\").iterdir())[0]\n",
    "\n",
    "# window = 3\n",
    "# temperature = 1.0\n",
    "\n",
    "# # ----------\n",
    "\n",
    "# _, logits, y_hats = lable_transform_video(\n",
    "#     video_path=video_path,\n",
    "#     horizontal_flips=[False, True],\n",
    "#     vertical_flips=[False, True],\n",
    "#     rotate_degrees=[0, -5, -10, 5, 10],\n",
    "#     translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "#     scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    "# )\n",
    "# y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_filtered_mean_gma_probabilities(y_hats: Tensor, ax):\n",
    "#     # select highest prediction\n",
    "#     pred = torch.argmax(y_hats, dim=2)\n",
    "#     y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "#     # remove inconsistent predictions\n",
    "#     for i in range(pred.shape[0]):\n",
    "#         for j in range(pred.shape[1]):\n",
    "#             min_j = max(0, j - window)\n",
    "#             max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "#             if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "#                 y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "#     # average of all transformations\n",
    "#     y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "#     # gaussian moving average\n",
    "#     distance = torch.arange(-gma_width, gma_width + 1, dtype=torch.float)\n",
    "#     gaussian = torch.exp(-(distance**2) / (2 * gma_sigma**2))\n",
    "\n",
    "#     weight_sum = torch.ones(y_hats.shape)\n",
    "#     weight_sum = F.pad(weight_sum, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "#     weight_sum = weight_sum.unfold(dimension=0, size=gma_window, step=1)\n",
    "#     weight_sum = weight_sum * gaussian\n",
    "#     weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "#     y_hats = F.pad(y_hats, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "#     y_hats = y_hats.unfold(dimension=0, size=gma_window, step=1)\n",
    "#     y_hats = y_hats * gaussian\n",
    "#     y_hats = torch.nansum(y_hats, dim=2)\n",
    "\n",
    "#     y_hats = y_hats / weight_sum\n",
    "\n",
    "#     plot_probabilities(y_hats, ax)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=2, nrows=1, tight_layout=True, figsize=(20, 5))\n",
    "\n",
    "# plot_probabilities(y_hats[0], axes[0])\n",
    "# axes[0].set_xlim(left=0, right=y_hats.shape[1])\n",
    "# axes[0].set_ylim(bottom=0, top=1)\n",
    "\n",
    "# plot_filtered_mean_gma_probabilities(y_hats, axes[1])\n",
    "# axes[1].set_xlim(left=0, right=y_hats.shape[1])\n",
    "# axes[1].set_ylim(bottom=0, top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_video(video_path: Path):\n",
    "    video_dense = []\n",
    "    video_logits = []\n",
    "    video_y_hats = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    for frame in _frame_iter(vidcap, \"Label frames\"):\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frame = frame.to(model.device)\n",
    "\n",
    "        batch_size = 128\n",
    "        batches = ceil(len(transforms) / batch_size)\n",
    "        batch_dense = []\n",
    "        batch_logits = []\n",
    "        batch_y_hats = []\n",
    "        for i in range(batches):\n",
    "            batch_transforms = transforms[i * batch_size : (i + 1) * batch_size]\n",
    "            frames = torch.stack([transform(frame) for transform in batch_transforms])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                dense, logits = model(frames)\n",
    "                y_hats = F.softmax(logits, dim=1)\n",
    "\n",
    "            batch_dense.append(dense.cpu())\n",
    "            batch_logits.append(logits.cpu())\n",
    "            batch_y_hats.append(y_hats.cpu())\n",
    "\n",
    "        video_dense.append(torch.cat(batch_dense, dim=0))\n",
    "        video_logits.append(torch.cat(batch_logits, dim=0))\n",
    "        video_y_hats.append(torch.cat(batch_y_hats, dim=0))\n",
    "\n",
    "    return torch.stack(video_dense, dim=1), torch.stack(video_logits, dim=1), torch.stack(video_y_hats, dim=1)\n",
    "\n",
    "\n",
    "def _frame_iter(capture, description):\n",
    "    def iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "\n",
    "    return tqdm(\n",
    "        iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def lable_transform_video(video_path, horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    global transforms\n",
    "\n",
    "    transforms = [\n",
    "        T.Compose(\n",
    "            [\n",
    "                T.Grayscale(),\n",
    "                T.Resize((165, 240), antialias=False),\n",
    "                HorizontalFlip(flip=horizontal_flip),\n",
    "                VerticalFlip(flip=vertical_flip),\n",
    "                Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "                T.ConvertImageDtype(torch.float32),\n",
    "            ]\n",
    "        )\n",
    "        for horizontal_flip, vertical_flip, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips, vertical_flips, rotate_degrees, translates, scales\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return label_video(video_path)\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[0]\n",
    "print(video_path.stem)\n",
    "\n",
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(y_hats, ax):\n",
    "    x = list(range(y_hats.shape[0]))\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x, y_hats[:, i], label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_best_probabilities(y_hats, ax):\n",
    "    x = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        x[best].append(i)\n",
    "        y[best].append(y_hat[best])\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=1, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def is_stable(y, i):\n",
    "    min_i = max(0, i - window)\n",
    "    max_i = min(i + window, len(y) - 1)\n",
    "\n",
    "    if min_i > i - window or max_i < i + window:\n",
    "        return False\n",
    "\n",
    "    for j in range(min_i, max_i + 1):\n",
    "        if y[j] == 0.0:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def plot_filtered_probabilities(y_hats, ax):\n",
    "    x = torch.arange(0, y_hats.shape[0]).int().repeat(y_hats.shape[1], 1).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], y_hats.shape[0])).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        y[best][i] = y_hat[best]\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        to_delete = []\n",
    "\n",
    "        for j in range(len(y[i])):\n",
    "            if not is_stable(y[i], j):\n",
    "                to_delete.append(j)\n",
    "\n",
    "        to_delete.sort(reverse=True)\n",
    "        for j in to_delete:\n",
    "            x[i].pop(j)\n",
    "            y[i].pop(j)\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=1, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_base_probabilities(y_hats):\n",
    "    ncols = 3\n",
    "    nrows = len(y_hats)\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=ncols,\n",
    "        nrows=nrows,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False,\n",
    "        tight_layout=True,\n",
    "        figsize=(10 * ncols, 5 * nrows),\n",
    "    )\n",
    "\n",
    "    for i in range(nrows):\n",
    "        plot_probabilities(y_hats[i], axes[i, 0])\n",
    "        plot_best_probabilities(y_hats[i], axes[i, 1])\n",
    "        plot_filtered_probabilities(y_hats[i], axes[i, 2])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax[0].set_xlim(left=0, right=y_hats.shape[1])\n",
    "        ax[0].set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "plot_base_probabilities(y_hats_[:1])\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_probabilities(y_hats[0], axes)\n",
    "# # plot_best_probabilities(y_hats[0], axes)\n",
    "# plot_filtered_probabilities(y_hats[0], axes)\n",
    "# axes.set_xlim(left=0, right=y_hats.shape[1])\n",
    "# axes.set_ylim(bottom=0, top=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of quality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [2.0, 3.0, 4.0], [3.0, 4.0, 5.0], [1.0, 3.0, 2.0], [1.0, 3.0, 2.0]],\n",
    "        [[1.0, 4.0, 2.0], [2.0, 4.0, 3.0], [3.0, 4.0, 6.0], [1.0, 4.0, 2.0], [1.0, 5.0, 2.0]],\n",
    "    ]\n",
    ")\n",
    "print(y_hats_.shape)\n",
    "\n",
    "pred = torch.argmax(y_hats_, dim=2)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "\n",
    "y_hats_ = y_hats_ * F.one_hot(pred)\n",
    "# mask = F.one_hot(pred) == 0\n",
    "# y_hats_ = torch.masked_fill(y_hats_, mask, 0.0)\n",
    "\n",
    "print(y_hats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        min_j = max(0, j - window)\n",
    "        max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "        if not torch.all(pred[i, min_j:max_j] == pred[i, j]):\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        if torch.sum(pred[i, j - window : j + window + 1] == pred[i, j]) < 1 + 2 * window:\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "print(y_hats_.shape)\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats__ = torch.mean(y_hats_, dim=0)\n",
    "print(y_hats__.shape)\n",
    "print(y_hats__)\n",
    "\n",
    "plates = y_hats__[:, :2]\n",
    "other = y_hats__[:, 2:]\n",
    "\n",
    "quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "print(quality)\n",
    "\n",
    "quality = quality / torch.sum(plates > 0, dim=1)\n",
    "zaro_mask = torch.eq(quality > 0, False)\n",
    "torch.masked_fill(quality, zaro_mask, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of quality value 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [2.0, 3.0, 4.0], [3.0, 4.0, 5.0], [1.0, 3.0, 2.0], [1.0, 3.0, 2.0]],\n",
    "        [[1.0, 4.0, 2.0], [2.0, 4.0, 3.0], [3.0, 4.0, 6.0], [1.0, 4.0, 2.0], [1.0, 5.0, 2.0]],\n",
    "    ]\n",
    ")\n",
    "print(y_hats_.shape)\n",
    "\n",
    "y_hats_ = torch.mean(y_hats_, 0)\n",
    "print(y_hats_.shape)\n",
    "print(y_hats_)\n",
    "\n",
    "# window moving average\n",
    "window = 1\n",
    "y_hats_ = F.pad(y_hats_, pad=(0, 0, window, window), mode=\"constant\", value=float(\"nan\"))\n",
    "y_hats_ = y_hats_.unfold(dimension=0, size=window * 2 + 1, step=1)\n",
    "y_hats_ = torch.nanmean(y_hats_, dim=2)\n",
    "\n",
    "print(y_hats_.shape)\n",
    "print(y_hats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [2.0, 2.0, 2.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        # [1.0, 2.0, 1.0],\n",
    "        # [2.0, 2.0, 1.0],\n",
    "        # [1.0, 2.0, 2.0],\n",
    "        # [2.0, 2.0, 2.0]\n",
    "    ]\n",
    ")\n",
    "print(\"y_hats:\\n\", y_hats_)\n",
    "print(\"\")\n",
    "\n",
    "width = 1\n",
    "window = width * 2 + 1\n",
    "sigma = window / 4\n",
    "distance = torch.arange(-width, width + 1, dtype=torch.float)\n",
    "gaussian = torch.exp(-(distance**2) / (2 * sigma**2))\n",
    "\n",
    "print(\"distance:\\n\", distance)\n",
    "print(\"gaussian:\\n\", gaussian)\n",
    "print(\"\")\n",
    "\n",
    "weight_sum = torch.ones(y_hats_.shape)\n",
    "weight_sum = F.pad(weight_sum, pad=(0, 0, width, width), mode=\"constant\", value=float(\"nan\"))\n",
    "weight_sum = weight_sum.unfold(dimension=0, size=window, step=1)\n",
    "weight_sum = weight_sum * gaussian\n",
    "weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "print(\"weight_sum:\\n\", weight_sum)\n",
    "print(\"\")\n",
    "\n",
    "y_hats_ = F.pad(y_hats_, pad=(0, 0, width, width), mode=\"constant\", value=float(\"nan\"))\n",
    "y_hats_ = y_hats_.unfold(dimension=0, size=window, step=1)\n",
    "y_hats_ = y_hats_ * gaussian\n",
    "y_hats_ = torch.nansum(y_hats_, dim=2)\n",
    "\n",
    "print(\"weighted_sum:\\n\", y_hats_)\n",
    "print(\"\")\n",
    "\n",
    "y_hats_ / weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [2.0, 2.0, 2.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        # [1.0, 2.0, 1.0],\n",
    "        # [2.0, 2.0, 1.0],\n",
    "        # [1.0, 2.0, 2.0],\n",
    "        # [2.0, 2.0, 2.0]\n",
    "    ]\n",
    ")\n",
    "width = 1\n",
    "window = width * 2 + 1\n",
    "sigma = window / 4\n",
    "distance = torch.arange(-width, width + 1, dtype=torch.float)\n",
    "gaussian = torch.exp(-(distance**2) / (2 * sigma**2))\n",
    "\n",
    "weight_sum = torch.ones(y_hats_.shape)\n",
    "weight_sum = F.pad(weight_sum, pad=(0, 0, width, width), mode=\"constant\", value=0)\n",
    "weight_sum = weight_sum.unfold(dimension=0, size=window, step=1)\n",
    "weight_sum = weight_sum * gaussian\n",
    "weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "y_hats_ = F.pad(y_hats_, pad=(0, 0, width, width), mode=\"constant\", value=0)\n",
    "y_hats_ = y_hats_.unfold(dimension=0, size=window, step=1)\n",
    "y_hats_ = y_hats_ * gaussian\n",
    "y_hats_ = torch.nansum(y_hats_, dim=2)\n",
    "\n",
    "y_hats_ / weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 5\n",
    "sigma = (width * 2 + 1) / 4\n",
    "\n",
    "distance = torch.arange(-width, width + 1, dtype=torch.float)\n",
    "gaussian = torch.exp(-(distance**2) / (2 * sigma**2))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "ax.plot(distance, gaussian)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "gaussian = signal.windows.gaussian(width * 2 + 1, std=sigma)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "ax.plot(distance, gaussian)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (the best prediction - sum of the rest prediction)\n",
    "a = y_hats_[:, :2]\n",
    "print(a)\n",
    "a = torch.amax(a, dim=1)\n",
    "print(a)\n",
    "a = a - torch.sum(y_hats_, dim=1)\n",
    "print(a)\n",
    "b = torch.eq(a > 0, False)\n",
    "a.masked_fill_(b, 0.0)\n",
    "\n",
    "# plates = y_hats[:, :3]\n",
    "# quality = torch.amax(plates, dim=1)\n",
    "# quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "# zaro_mask = torch.eq(quality > 0, False)\n",
    "# quality.masked_fill_(zaro_mask, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate quality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality(y_hats: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=1, nrows=3, tight_layout=True, figsize=(10, 15))\n",
    "\n",
    "    plot_mean_filtered_probabilities(y_hats, axes[0])\n",
    "    plot_quality_dots(quality, axes[1])\n",
    "    plot_quality_line(quality, axes[2])\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_mean_filtered_probabilities(y_hats: Tensor, ax):\n",
    "    for i, label in enumerate(label_def):\n",
    "        x, y = extract_nonzero_values(y_hats[:, i])\n",
    "        ax.plot(x, y, \"o\", markersize=1, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(y_hats))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def plot_quality_dots(quality: Tensor, ax):\n",
    "    ax.plot(range(len(quality)), quality, \"o\", markersize=2, color=\"tab:gray\")\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(quality))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def plot_quality_line(quality: Tensor, ax):\n",
    "    ax.plot(range(len(quality)), quality, color=\"tab:gray\")\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(quality))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "def extract_nonzero_values(y_hats):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        if y_hat > 0:\n",
    "            x.append(i)\n",
    "            y.append(y_hat)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality2(y_hats_: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, tight_layout=True, figsize=(20, 5))\n",
    "\n",
    "    plot_probabilities(y_hats_, axes[0])\n",
    "    plot_quality_line(quality, axes[1])\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def calculate_quality(y_hats: Tensor):  # test (mean + rolling window mean)\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # rolling window average\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, window, window), mode=\"constant\", value=float(\"nan\"))\n",
    "    y_hats = y_hats.unfold(dimension=0, size=window * 2 + 1, step=1)\n",
    "    y_hats = torch.nanmean(y_hats, dim=2)\n",
    "\n",
    "    # the best prediction\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "plot_probabilities(torch.mean(F.softmax(logits / temperature, dim=2), dim=0), axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # test (mean + rolling window mean + normalization)\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # rolling window average\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, window, window), mode=\"constant\", value=float(\"nan\"))\n",
    "    y_hats = y_hats.unfold(dimension=0, size=window * 2 + 1, step=1)\n",
    "    y_hats = torch.nanmean(y_hats, dim=2)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # test (best + mean + normalization)\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # test (best + mean + rolling window mean + normalization)\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # rolling window average\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, window, window), mode=\"constant\", value=float(\"nan\"))\n",
    "    y_hats = y_hats.unfold(dimension=0, size=window * 2 + 1, step=1)\n",
    "    y_hats = torch.nanmean(y_hats, dim=2)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # Selected (best + remove unstable + mean + normalization)\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # test (best + remove unstable + mean + rolling window mean + normalization)\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # rolling window average\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, window, window), mode=\"constant\", value=float(\"nan\"))\n",
    "    y_hats = y_hats.unfold(dimension=0, size=window * 2 + 1, step=1)\n",
    "    y_hats = torch.nanmean(y_hats, dim=2)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):  # test (mean + Gaussian moving average + normalization)\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # gaussian moving average\n",
    "    distance = torch.arange(-gma_width, gma_width + 1, dtype=torch.float)\n",
    "    gaussian = torch.exp(-(distance**2) / (2 * gma_sigma**2))\n",
    "\n",
    "    weight_sum = torch.ones(y_hats.shape)\n",
    "    weight_sum = F.pad(weight_sum, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    weight_sum = weight_sum.unfold(dimension=0, size=gma_window, step=1)\n",
    "    weight_sum = weight_sum * gaussian\n",
    "    weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    y_hats = y_hats.unfold(dimension=0, size=gma_window, step=1)\n",
    "    y_hats = y_hats * gaussian\n",
    "    y_hats = torch.nansum(y_hats, dim=2)\n",
    "\n",
    "    y_hats = y_hats / weight_sum\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "\n",
    "gma_width = 3\n",
    "gma_window = gma_width * 2 + 1\n",
    "gma_sigma = gma_window / 4\n",
    "\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(\n",
    "    y_hats: Tensor,\n",
    "):  # new selected (best + remove unstable + mean + Gaussian moving average + normalization)\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # gaussian moving average\n",
    "    distance = torch.arange(-gma_width, gma_width + 1, dtype=torch.float)\n",
    "    gaussian = torch.exp(-(distance**2) / (2 * gma_sigma**2))\n",
    "\n",
    "    weight_sum = torch.ones(y_hats.shape)\n",
    "    weight_sum = F.pad(weight_sum, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    weight_sum = weight_sum.unfold(dimension=0, size=gma_window, step=1)\n",
    "    weight_sum = weight_sum * gaussian\n",
    "    weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    y_hats = y_hats.unfold(dimension=0, size=gma_window, step=1)\n",
    "    y_hats = y_hats * gaussian\n",
    "    y_hats = torch.nansum(y_hats, dim=2)\n",
    "\n",
    "    y_hats = y_hats / weight_sum\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    plates = y_hats[:, :3]\n",
    "    quality = torch.amax(plates, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "\n",
    "gma_width = 3\n",
    "gma_window = gma_width * 2 + 1\n",
    "gma_sigma = gma_window / 4\n",
    "\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_dots(quality, axes)\n",
    "# # plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)  # ???\n",
    "\n",
    "    # (sum planes' prediction - sum no planes' prediction) / (number of planes' prediction greater than 0)\n",
    "    plates = y_hats[:, :3]\n",
    "    other = y_hats[:, 3:]\n",
    "    quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "    quality = quality / torch.sum(plates > 0, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(y_hats: Tensor):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # (the best prediction - sum of the rest prediction)\n",
    "    quality = torch.amax(y_hats, dim=1)\n",
    "    quality = (quality * 2) - torch.sum(y_hats, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "# y_hats_ = y_hats.clone()\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "# plot_quality(y_hats_, quality).show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "plot_quality_dots(quality, axes)\n",
    "# plot_quality_line(quality, axes)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logits(data_path: Path):\n",
    "    dense = []\n",
    "    for video_path in sorted(data_path.iterdir()):\n",
    "        path = sorted(video_path.iterdir())[0]\n",
    "        logits, _, _ = torch.load(path)\n",
    "        dense.append(logits)\n",
    "    return torch.cat(dense)\n",
    "\n",
    "\n",
    "def save_std_mean(data_path: Path, logits):\n",
    "    std_mean = torch.std_mean(logits, unbiased=False, dim=0)\n",
    "    torch.save(std_mean, f\"{data_path}/std_mean.pt\")\n",
    "    print(std_mean[0].shape)\n",
    "\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS_tran_\" / \"data\"\n",
    "dense = load_logits(path / \"train\")\n",
    "save_std_mean(path, dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transfor operation to quality plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[0]\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality(y_hats: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, tight_layout=True, figsize=(20, 5))\n",
    "\n",
    "    plot_mean_filtered_probabilities(y_hats, axes[0])\n",
    "    plot_quality_line(quality, axes[1])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation (-15, -10, ..., 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translates -+10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale 100-120%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -15, 15],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.2],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(10, 5))\n",
    "# # plot_mean_filtered_probabilities(y_hats_, axes)\n",
    "# plot_quality_line(quality, axes)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "plot_base_probabilities(y_hats_[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_video(checkpoint_file):\n",
    "    global model\n",
    "\n",
    "    checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "    model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "    # disable randomness, dropout, etc...\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # _, logits, y_hats = lable_transform_video(\n",
    "    #     video_path=video_path,\n",
    "    #     horizontal_flips=[False],\n",
    "    #     vertical_flips=[False],\n",
    "    #     rotate_degrees=[0],\n",
    "    #     translates=[(0.0, 0.0)],\n",
    "    #     scales=[1.0],\n",
    "    # )\n",
    "    _, logits, y_hats = lable_transform_video(\n",
    "        video_path=video_path,\n",
    "        horizontal_flips=[False, True],\n",
    "        vertical_flips=[False, True],\n",
    "        rotate_degrees=[0, -5, -10, 5, 10],\n",
    "        translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "        scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    "    )\n",
    "    # _, logits, y_hats = lable_transform_video(\n",
    "    #     video_path=video_path,\n",
    "    #     horizontal_flips=[False, True],\n",
    "    #     vertical_flips=[False, True],\n",
    "    #     rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    #     translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    #     scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    "    # )\n",
    "\n",
    "    y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "    y_hats_, quality = calculate_quality(y_hats_)\n",
    "    plot_quality(y_hats_, quality).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[1]\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 0\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[0]\n",
    "test_video(checkpoint_file=root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-09_15-55-39\" / \"0\")  # feager-deluge-2718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of quality plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[0]\n",
    "\n",
    "window = 3\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_1_class_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "x = list(range(y_hats[0].shape[0]))\n",
    "for i, label in enumerate(label_def):\n",
    "    ax.plot(x, y_hats[0][:, i], \"o\", markersize=1, label=label)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_1_class_probability_dotted.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_best_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_2_highest_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_filtered_probabilities(y_hats[0], ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_3_stable_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_mean_probabilities(y_hats: Tensor, ax):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove inconsistent predictions\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        x, y = extract_nonzero_values(y_hats[:, i])\n",
    "        ax.plot(x, y, \"o\", markersize=1, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(y_hats))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_filtered_mean_probabilities(y_hats, ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_4_mean_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_mean_gma_probabilities(y_hats: Tensor, ax):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    y_hats = y_hats * F.one_hot(pred, num_classes=y_hats.shape[2])\n",
    "\n",
    "    # remove inconsistent predictions\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # gaussian moving average\n",
    "    distance = torch.arange(-gma_width, gma_width + 1, dtype=torch.float)\n",
    "    gaussian = torch.exp(-(distance**2) / (2 * gma_sigma**2))\n",
    "\n",
    "    weight_sum = torch.ones(y_hats.shape)\n",
    "    weight_sum = F.pad(weight_sum, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    weight_sum = weight_sum.unfold(dimension=0, size=gma_window, step=1)\n",
    "    weight_sum = weight_sum * gaussian\n",
    "    weight_sum = torch.nansum(weight_sum, dim=2)\n",
    "\n",
    "    y_hats = F.pad(y_hats, pad=(0, 0, gma_width, gma_width), mode=\"constant\", value=0)\n",
    "    y_hats = y_hats.unfold(dimension=0, size=gma_window, step=1)\n",
    "    y_hats = y_hats * gaussian\n",
    "    y_hats = torch.nansum(y_hats, dim=2)\n",
    "\n",
    "    y_hats = y_hats / weight_sum\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        x, y = extract_nonzero_values(y_hats[:, i])\n",
    "        ax.plot(x, y, \"o\", markersize=1, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "    ax.set_xlim(left=0, right=len(y_hats))\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "plot_filtered_mean_gma_probabilities(y_hats, ax)\n",
    "\n",
    "ax.set_xlim(left=0, right=y_hats.shape[1])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Probability\", size=\"large\")  # , size=\"16\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")  # , size=\"16\")\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_5_gmv_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3))\n",
    "\n",
    "\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "y_hats_, quality = calculate_quality(y_hats_)\n",
    "\n",
    "ax.plot(range(len(quality)), quality, color=\"tab:cyan\")\n",
    "\n",
    "ax.set_xlim(left=0, right=len(quality))\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality\", size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/quality_6_frame_quality.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate frames quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (165, 240)\n",
    "\n",
    "videoFrames = VideosFrameDataset(\n",
    "    video_path=video_path,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize(img_size, antialias=True),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "samples = 5\n",
    "beans = 10\n",
    "\n",
    "nrows = 1\n",
    "figsize = 1.5\n",
    "scale = img_size[0] / img_size[1]\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=nrows,\n",
    "    squeeze=True,\n",
    "    tight_layout=True,\n",
    "    figsize=(figsize * samples, figsize * scale * nrows * 3),\n",
    "    #     figsize=(7, 3)\n",
    "    #     dpi=600,\n",
    ")\n",
    "\n",
    "\n",
    "min_quality = 0.3\n",
    "y_hat = quality\n",
    "preds = torch.argmax(y_hats[0], dim=1)\n",
    "qualities = []\n",
    "\n",
    "rows = []\n",
    "# For each label\n",
    "for j in range(3):\n",
    "    mask = torch.ne(preds, j)\n",
    "    y_hat_label = torch.masked_fill(y_hat, mask, 0)\n",
    "    # y_hat_label[:25] = 0  # omit first 25 frames\n",
    "    best = torch.argsort(y_hat_label, descending=True)\n",
    "\n",
    "    # delete frames from other classes and low quality frames\n",
    "    best = [idx.item() for idx in best if y_hat_label[idx] != 0 and y_hat_label[idx] > min_quality]\n",
    "\n",
    "    bean_size = int(len(best) / beans) + 1\n",
    "    samples_ = [idx for i, idx in enumerate(best) if i % bean_size == 0][:samples]\n",
    "\n",
    "    # for each sample\n",
    "    frames = [videoFrames[idx] for idx in reversed(samples_)]\n",
    "    row = torch.cat(frames, dim=2)\n",
    "    rows.append(row)\n",
    "\n",
    "    qualities.extend([y_hat[idx].item() for idx in reversed(samples_)])\n",
    "\n",
    "img = torch.cat(rows, dim=1)\n",
    "img = TF.to_pil_image(img)\n",
    "img = TF.to_grayscale(img)\n",
    "img = np.asarray(img)\n",
    "axes.imshow(img, cmap=\"gray\")\n",
    "axes.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "for col_idx in range(samples):\n",
    "    for label_idx in range(3):\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 10,\n",
    "            round(qualities[label_idx * samples + col_idx], 2),\n",
    "            size=\"large\",\n",
    "            color=\"tab:cyan\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "\n",
    "for label_idx in range(3):\n",
    "    axes.text(\n",
    "        -30,\n",
    "        img_size[0] * label_idx + img_size[0] / 2,\n",
    "        label_def[label_idx].replace(\"-\", \"\\n\"),\n",
    "        rotation=90,\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Standard Planes\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/samples_planes.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate video\n",
    "Add quality value to a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poprawne\n",
    "# video_path = root / \"data\" / \"US_VIDEOS\" / \"videos\" / \"test\" / \"IMG_20220105_1_1.mp4\"\n",
    "# video_path = root / \"data\" / \"US_VIDEOS\" / \"videos\" / \"test\" / \"IMG_20220531101504_0133.AVI\"\n",
    "# video_path = root / \"data\" / \"US_VIDEOS\" / \"videos\" / \"train\" / \"IMG_20220531101504_0054.AVI\"\n",
    "\n",
    "# nie poprawne\n",
    "# video_path = root / \"data\" / \"US_VIDEOS\" / \"IMG_20211222_2_chor.avi\"\n",
    "video_path = root / \"data\" / \"US_VIDEOS\" / \"IMG_20220615_2_19_Nieprawidow_przykad.mp4\"\n",
    "\n",
    "video_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False],\n",
    "    vertical_flips=[False],\n",
    "    rotate_degrees=[0],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.00],\n",
    ")\n",
    "y_hats_, quality = calculate_quality(y_hats)\n",
    "quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.00, 1.05, 1.10, 1.15, 1.20],\n",
    ")\n",
    "y_hats_, quality = calculate_quality(y_hats)\n",
    "quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text(frame, text, row):\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        text,\n",
    "        (column_padding, row_padding + row_size * row),\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        1.5,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "        cv2.LINE_8,\n",
    "    )\n",
    "\n",
    "\n",
    "def put_probability_line(frame, probability, row):\n",
    "    x = column_padding + 110\n",
    "    y = row_padding - 15 + row_size * row\n",
    "\n",
    "    cv2.line(frame, (x, y), (x + int(100 * probability), y), (0, 255, 255), 5)\n",
    "\n",
    "\n",
    "def add_quality_to_video(video_path: Path, result_path: Path, quality: Tensor, y_hats: Tensor):\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    size = (frame_width, frame_height)\n",
    "    result = cv2.VideoWriter(str(result_path), cv2.VideoWriter_fourcc(*\"avc1\"), fps, size)\n",
    "\n",
    "    for frame, q, y_hat in zip(_frame_iter(vidcap, \"Label frames\"), quality, y_hats):\n",
    "        put_text(frame, f\"QV: {q:.2f}\", 1)\n",
    "\n",
    "        put_text(frame, \"TV:\", 2)\n",
    "        put_text(frame, \"TT:\", 3)\n",
    "        put_text(frame, \"TC:\", 4)\n",
    "        put_text(frame, \"OT:\", 5)\n",
    "        put_text(frame, \"NB:\", 6)\n",
    "\n",
    "        for i, probability in enumerate(y_hat):\n",
    "            # print(probability.item())\n",
    "            put_probability_line(frame, probability.item(), i + 2)\n",
    "\n",
    "        result.write(frame)\n",
    "\n",
    "    result.release()\n",
    "    vidcap.release()\n",
    "\n",
    "\n",
    "column_padding = 20\n",
    "row_padding = 20\n",
    "row_size = 50\n",
    "\n",
    "result_video_path = root / \"data\" / \"US_VIDEOS_QUALITY\" / (video_path.stem + \".mp4\")\n",
    "\n",
    "add_quality_to_video(\n",
    "    video_path=video_path,\n",
    "    result_path=result_video_path,\n",
    "    quality=quality,\n",
    "    y_hats=y_hats[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video.from_file(str(result_video_path), width=500, loop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_durations_statistics(path: Path):\n",
    "    videos_path = path / \"videos\"\n",
    "    durations = torch.cat(\n",
    "        [\n",
    "            video_durations(videos_path / \"train\"),\n",
    "            video_durations(videos_path / \"test\"),\n",
    "        ]\n",
    "    )\n",
    "    return durations.min(), durations.max(), torch.std_mean(durations)\n",
    "\n",
    "\n",
    "def video_durations(videos_path: Path):\n",
    "    durations = []\n",
    "    videos = sorted(videos_path.iterdir())\n",
    "    for video_path in tqdm(videos, desc=\"cound duration videos\"):\n",
    "        durations.append(video_duration(video_path))\n",
    "\n",
    "    return torch.tensor(durations)\n",
    "\n",
    "\n",
    "def video_duration(video_path: Path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count / fps\n",
    "\n",
    "\n",
    "min_duration, max_duration, (std_duration, mean_duration) = video_durations_statistics(videos_path)\n",
    "\n",
    "print(\"Duration\")\n",
    "print(f\"min {min_duration}\")\n",
    "print(f\"max {max_duration}\")\n",
    "print(f\"std {std_duration}\")\n",
    "print(f\"mean {mean_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-29_07-06-08\"  # deep-water-1006\n",
    "\n",
    "print(sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\")))\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "rnn = QualityLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "rnn.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-29_07-06-08\"  # deep-water-1006\n",
    "\n",
    "print(sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\")))\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "rnn = QualityLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "rnn.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoQualityDataset(\n",
    "    data_dir=root / \"data\",\n",
    "    dataset_name=\"US_VIDEOS_tran_0500\",\n",
    "    train=False,\n",
    "    seq_len=0,\n",
    "    normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn(i):\n",
    "    x, y, preds = dataset[i]\n",
    "    x = x.to(device=rnn.device)\n",
    "    y = y.to(device=rnn.device)\n",
    "    with torch.no_grad():\n",
    "        y_hat = rnn(x.unsqueeze(0)).squeeze()\n",
    "    return y.cpu(), y_hat.cpu(), preds\n",
    "\n",
    "\n",
    "y, y_hat, preds = test_rnn(0)\n",
    "\n",
    "\n",
    "label_def = FetalBrainPlanesDataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3), dpi=300)\n",
    "\n",
    "x = list(range(len(y)))\n",
    "ax.plot(x, y, label=\"true\", color=\"tab:gray\")\n",
    "ax.plot(x, y_hat, label=\"predicted\", color=\"tab:cyan\")\n",
    "\n",
    "ax.set_xlim(left=0, right=len(y_hat))\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality\", size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "ax.legend(fontsize=\"small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_frame_quality_to_true_frame_quality.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "video_path = sorted((videos_path / \"videos\" / \"test\").iterdir())[0]\n",
    "print(video_path.stem)\n",
    "\n",
    "_, logits, y_hats = lable_transform_video(\n",
    "    video_path=video_path,\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    scales=[1.0, 1.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3), dpi=300)\n",
    "\n",
    "# plot_best_probabilities(y_hats[0], ax)\n",
    "plot_best_probabilities(torch.mean(y_hats, dim=0), ax)\n",
    "\n",
    "x = list(range(len(y)))\n",
    "ax.plot(x, y_hat, label=\"predicted\", color=\"tab:cyan\")\n",
    "\n",
    "ax.set_xlim(left=0, right=len(y_hat))\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality \\\\ probability\".replace(\"_\", \"\\n\"), size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "ax.legend(fontsize=\"x-small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_frame_quality_to_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, tight_layout=True, figsize=(6, 3), dpi=300)\n",
    "\n",
    "# plot_best_probabilities(y_hats[0], ax)\n",
    "plot_best_probabilities(torch.mean(y_hats, dim=0), ax)\n",
    "\n",
    "x = list(range(len(y)))\n",
    "ax.plot(x, y, label=\"true\", color=\"tab:gray\")\n",
    "\n",
    "ax.set_xlim(left=0, right=len(y))\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "plt.ylabel(\"Frame quality \\\\ probability\".replace(\"_\", \"\\n\"), size=\"large\")\n",
    "plt.xlabel(\"Video frame index\", size=\"large\")\n",
    "ax.legend(fontsize=\"x-small\", loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_true_frame_quality_to_probability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (165, 240)\n",
    "\n",
    "videos = USVideosFrameDataset(\n",
    "    data_dir=str(root / \"data\"),\n",
    "    dataset_name=\"US_VIDEOS\",\n",
    "    train=False,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize(img_size, antialias=True),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "min_quality = 0.3\n",
    "samples = 5\n",
    "beans = 10\n",
    "\n",
    "nrows = 1\n",
    "figsize = 1.5\n",
    "scale = img_size[0] / img_size[1]\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=nrows,\n",
    "    squeeze=True,\n",
    "    tight_layout=True,\n",
    "    figsize=(figsize * samples, figsize * scale * nrows * 3),\n",
    "    #     figsize=(7, 3)\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "\n",
    "qualities = []\n",
    "true_qualities = []\n",
    "\n",
    "rows = []\n",
    "# For each label\n",
    "for j in range(3):\n",
    "    mask = torch.ne(preds, j)\n",
    "    y_hat_label = torch.masked_fill(y_hat, mask, 0)\n",
    "    # y_hat_label[:25] = 0  # omit first 25 frames\n",
    "    best = torch.argsort(y_hat_label, descending=True)\n",
    "\n",
    "    # delete frames from other classes and low quality frames\n",
    "    best = [idx.item() for idx in best if y_hat_label[idx] != 0 and y_hat_label[idx] > min_quality]\n",
    "\n",
    "    bean_size = int(len(best) / beans) + 1\n",
    "    samples_ = [idx for i, idx in enumerate(best) if i % bean_size == 0][:samples]\n",
    "\n",
    "    # for each sample\n",
    "    frames = [videos[0, idx] for idx in reversed(samples_)]\n",
    "    row = torch.cat(frames, dim=2)\n",
    "    rows.append(row)\n",
    "\n",
    "    qualities.extend([y_hat[idx].item() for idx in reversed(samples_)])\n",
    "    true_qualities.extend([y[idx].item() for idx in reversed(samples_)])\n",
    "\n",
    "img = torch.cat(rows, dim=1)\n",
    "img = TF.to_pil_image(img)\n",
    "img = TF.to_grayscale(img)\n",
    "img = np.asarray(img)\n",
    "axes.imshow(img, cmap=\"gray\")\n",
    "axes.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "for col_idx in range(samples):\n",
    "    for label_idx in range(3):\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 10,\n",
    "            f\"{qualities[label_idx * samples + col_idx]:.2f}\",\n",
    "            size=\"large\",\n",
    "            color=\"tab:cyan\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "        axes.text(\n",
    "            img_size[1] * col_idx + img_size[1] - 10,\n",
    "            img_size[0] * label_idx + 41,\n",
    "            f\"{true_qualities[label_idx * samples + col_idx]:.2f}\",\n",
    "            size=\"large\",\n",
    "            color=\"tab:gray\",\n",
    "            bbox={\"pad\": 0, \"color\": (0, 0, 0, 0.3)},\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "        )\n",
    "\n",
    "for label_idx in range(3):\n",
    "    axes.text(\n",
    "        -30,\n",
    "        img_size[0] * label_idx + img_size[0] / 2,\n",
    "        label_def[label_idx].replace(\"-\", \"\\n\"),\n",
    "        rotation=90,\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Standard Planes\", size=\"large\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/result_samples_planes.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
