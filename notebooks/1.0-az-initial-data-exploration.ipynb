{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.utils.data import ConcatDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.components.dataset import FetalPlanesDataset\n",
    "from src.data.components.transforms import RandomPercentCrop\n",
    "\n",
    "database_dir = root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset(\n",
    "    [\n",
    "        FetalPlanesDataset(data_dir=database_dir, train=True),\n",
    "        # FetalPlanesDataset(data_dir=database_dir, train=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs, tick_labels: bool = True):\n",
    "    n = ceil(sqrt(len(imgs)))\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=n, nrows=n, squeeze=False, figsize=(20, 15))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i * n + j >= len(imgs):\n",
    "                continue\n",
    "\n",
    "            img, label = imgs[i * n + j]\n",
    "            img = img.detach()\n",
    "            img = F.to_pil_image(img)\n",
    "            img = F.to_grayscale(img)\n",
    "            axes[i, j].imshow(np.asarray(img), cmap=\"gray\")\n",
    "            axes[i, j].set_xlabel(label)\n",
    "            if not tick_labels:\n",
    "                axes[i, j].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show([dataset[i] for i in np.random.permutation(len(dataset))[:25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=iter(tqdm(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame(data=[(i.shape[0], i.shape[1], i.shape[2]) for i in df[0]])\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_shape.mean()\n",
    "median = df_shape.median()\n",
    "\n",
    "axs = df_shape.hist(column=[1, 2], bins=100, figsize=(20, 5))\n",
    "\n",
    "axs[0][0].axvline(mean[1], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 572.415\n",
    "axs[0][1].axvline(mean[2], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 661.0\n",
    "axs[0][0].axvline(median[1], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 857.255\n",
    "axs[0][1].axvline(median[2], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 959.0\n",
    "axs[0][0].legend([f\"mean {mean[1]}\", f\"median {median[1]}\"], loc=\"upper left\")\n",
    "axs[0][1].legend([f\"mean {mean[2]}\", f\"median {median[2]}\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = median[2] / median[1]\n",
    "80 / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, = (\n",
    "        0,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    for data, _ in tqdm(dataset):\n",
    "        channels_sum += torch.mean(data, dim=[1, 2])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[1, 2])\n",
    "\n",
    "    mean = channels_sum / len(dataset)\n",
    "    std = (channels_sqrd_sum / len(dataset) - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "train = FetalPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        T.Resize((165, 240)),\n",
    "    ),\n",
    ")\n",
    "\n",
    "mean, std = get_mean_std(train)\n",
    "print(mean.item())  # 0.16958117485046387, 0.16958120197261892\n",
    "print(std.item())  # 0.1906554251909256,  0.19065533816416103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = FetalPlanesDataset(\n",
    "#     data_dir=database_dir,\n",
    "#     train=True,\n",
    "#     transform=torch.nn.Sequential(\n",
    "#         T.Grayscale(),\n",
    "#         T.ConvertImageDtype(torch.float32),\n",
    "#         RandomPercentCrop(max_percent=20),\n",
    "#         T.RandomHorizontalFlip(p=0.5),\n",
    "#         # T.RandomAffine(degrees=15, fill=1),\n",
    "#         T.RandomAffine(degrees=0, translate=(0.1, 0.1), fill=1),\n",
    "#         # T.RandomAffine(degrees=0, scale=(1.0, 1.2), fill=1),\n",
    "#         # T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(1.0, 1.2)),\n",
    "#         T.Resize((170, 250)),  # (55, 80), (70, 100), (100, 150), (170, 250)\n",
    "#         # Normalize(mean=mean, std=std)\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "train = FetalPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        T.Resize((170, 250)),\n",
    "    ),\n",
    ")\n",
    "\n",
    "show([train[i] for i in np.random.permutation(len(train))[:49]], tick_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_split_label(\n",
    "    dataset: pd.DataFrame, test_size: float, groups, random_state: int = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=random_state)\n",
    "    split = splitter.split(dataset, groups=groups)\n",
    "    train_idx, test_idx = next(split)\n",
    "    return dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
    "\n",
    "\n",
    "def get_similarity(train, test, test_size):\n",
    "    similarity = 0\n",
    "    train_count = train.value_counts(sort=False).sort_index()\n",
    "    test_count = test.value_counts(sort=False).sort_index()\n",
    "\n",
    "    if train_count.index.tolist() != test_count.index.tolist():\n",
    "        return -1\n",
    "\n",
    "    for (a, b) in zip(train_count, test_count):\n",
    "        similarity += (a * test_size - b * (1 - test_size)) ** 2\n",
    "    return similarity**0.5\n",
    "\n",
    "\n",
    "def plt_value_counts(ax, dataset, tile=None):\n",
    "    counts = dataset.value_counts(sort=False).sort_index()\n",
    "    counts.plot(kind=\"bar\", ax=ax)\n",
    "    if tile:\n",
    "        ax.set_title(tile)\n",
    "\n",
    "\n",
    "def plt_group_split(\n",
    "    dataset: pd.DataFrame, test_size: float, random_states: List[int], top_states: int = None\n",
    "):\n",
    "    splits = []\n",
    "    for random_state in tqdm(random_states):\n",
    "        tr, val = group_split_label(\n",
    "            dataset,\n",
    "            test_size=test_size,\n",
    "            groups=dataset[\"Patient_num\"],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        similarity = get_similarity(tr.Plane, val.Plane, test_size)\n",
    "        if similarity >= 0:\n",
    "            splits.append((similarity, tr, val, random_state))\n",
    "\n",
    "    splits.sort(key=lambda e: (e[0], e[3]))\n",
    "    nrows = top_states if top_states else len(splits)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=2,\n",
    "        sharex=\"all\",\n",
    "        squeeze=False,\n",
    "        figsize=(20, 3 * nrows),\n",
    "    )\n",
    "    fig.suptitle(f\"Test size {test_size}\")\n",
    "    for (i, (similarity, tr, val, random_state)) in enumerate(splits[:nrows]):\n",
    "        plt_value_counts(axes[i, 0], tr.Plane, tile=f\"Seed {random_state}\")\n",
    "        plt_value_counts(axes[i, 1], val.Plane, tile=f\"Similarity {similarity}\")\n",
    "\n",
    "    plt.show()\n",
    "    print([random_state for (similarity, tr, val, random_state) in splits[:nrows]])\n",
    "\n",
    "\n",
    "plt_group_split(\n",
    "    train.img_labels,\n",
    "    test_size=0.2,\n",
    "    random_states=list(range(1000)),\n",
    "    top_states=3,\n",
    ")  # 9521, 3397, 4078, 6127, 1434, 4424, 8613, 8823, 9185, 3218\n",
    "plt_group_split(\n",
    "    train.img_labels,\n",
    "    test_size=0.15,\n",
    "    random_states=list(range(1000)),\n",
    "    top_states=3,\n",
    ")  # 34, 1208, 2971, 9081, 8517, 8176, 640, 3679, 5951, 8733\n",
    "plt_group_split(\n",
    "    train.img_labels,\n",
    "    test_size=0.1,\n",
    "    random_states=list(range(1000)),\n",
    "    top_states=3,\n",
    ")  # 8166"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
