{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rootutils\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.utils.data import ConcatDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import FetalBrainPlanesDataset\n",
    "from src.data.components.transforms import RandomPercentCrop\n",
    "from src.data.utils.utils import show_pytorch_images\n",
    "\n",
    "database_dir = root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset(\n",
    "    [\n",
    "        FetalBrainPlanesDataset(data_dir=database_dir, train=True),\n",
    "        # FetalBrainPlanesDataset(data_dir=database_dir, train=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pytorch_images(\n",
    "    [dataset[i] for i in np.random.permutation(len(dataset))[:25]],\n",
    "    tick_labels=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=iter(tqdm(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame(data=[(i.shape[0], i.shape[1], i.shape[2]) for i in df[0]])\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_shape.mean()\n",
    "median = df_shape.median()\n",
    "\n",
    "axs = df_shape.hist(column=[1, 2], bins=100, figsize=(20, 5))\n",
    "\n",
    "axs[0][0].axvline(mean[1], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 572.415\n",
    "axs[0][1].axvline(mean[2], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 661.0\n",
    "axs[0][0].axvline(median[1], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 857.255\n",
    "axs[0][1].axvline(median[2], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 959.0\n",
    "axs[0][0].legend([f\"mean {mean[1]}\", f\"median {median[1]}\"], loc=\"upper left\")\n",
    "axs[0][1].legend([f\"mean {mean[2]}\", f\"median {median[2]}\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = median[2] / median[1]\n",
    "\n",
    "\n",
    "def print_resolution(width):\n",
    "    height = width / scale\n",
    "    print(f\"{height:.2f} / {width}\")\n",
    "\n",
    "\n",
    "print_resolution(80)  # 55 / 80\n",
    "print_resolution(100)  # 70 / 100\n",
    "print_resolution(150)  # 100 / 150\n",
    "print_resolution(240)  # 165 / 240\n",
    "\n",
    "print_resolution(300)  # 205 / 300\n",
    "print_resolution(400)  # 275 / 400\n",
    "print_resolution(500)  # 345 / 500\n",
    "print_resolution(600)  # 415 / 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    (\n",
    "        channels_sum,\n",
    "        channels_sqrd_sum,\n",
    "    ) = (\n",
    "        0,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    for data, _ in tqdm(dataset):\n",
    "        channels_sum += torch.mean(data, dim=[1, 2])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[1, 2])\n",
    "\n",
    "    mean = channels_sum / len(dataset)\n",
    "    std = (channels_sqrd_sum / len(dataset) - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def find_mean_std(height, width):\n",
    "    train = FetalBrainPlanesDataset(\n",
    "        data_dir=database_dir,\n",
    "        train=True,\n",
    "        transform=torch.nn.Sequential(\n",
    "            T.Grayscale(),\n",
    "            T.Resize((height, width)),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    mean, std = get_mean_std(train)\n",
    "    print(f\"For {height} / {width} mean is {mean.item():.2f} std is {std.item():.2f}\")\n",
    "\n",
    "\n",
    "# print(mean.item())  # 0.16958117485046387, 0.16958120197261892\n",
    "# print(std.item())  # 0.1906554251909256,  0.19065533816416103\n",
    "find_mean_std(55, 80)  # 0.17 / 0.19\n",
    "find_mean_std(165, 240)  # 0.17 / 0.19\n",
    "find_mean_std(415, 600)  # 0.17 / 0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        # RandomPercentCrop(max_percent=20),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        # T.RandomHorizontalFlip(p=0.5),\n",
    "        # T.RandomAffine(degrees=15, fill=255),\n",
    "        # T.RandomAffine(degrees=0, translate=(0.1, 0.1), fill=255),\n",
    "        # T.RandomAffine(degrees=0, scale=(1.0, 1.2), fill=255),\n",
    "        # T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(1.0, 1.2), fill=255),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        # T.Normalize(mean=0.17, std=0.19),\n",
    "    ),\n",
    ")\n",
    "\n",
    "show_pytorch_images([train[i] for i in np.random.permutation(len(train))][:49]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240)),\n",
    "        T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "        # T.RandAugment(),\n",
    "        # T.TrivialAugmentWide(),\n",
    "        # T.AugMix(),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "show_pytorch_images([train[i] for i in np.random.permutation(len(train))][:49]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_split_label(\n",
    "    dataset: pd.DataFrame, test_size: float, groups, random_state: int = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=random_state)\n",
    "    split = splitter.split(dataset, groups=groups)\n",
    "    train_idx, test_idx = next(split)\n",
    "    return dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
    "\n",
    "\n",
    "def get_similarity(train, test, test_size):\n",
    "    similarity = 0\n",
    "    train_count = train.value_counts(sort=False).sort_index()\n",
    "    test_count = test.value_counts(sort=False).sort_index()\n",
    "\n",
    "    if train_count.index.tolist() != test_count.index.tolist():\n",
    "        return -1\n",
    "\n",
    "    for a, b in zip(train_count, test_count):\n",
    "        similarity += (a * test_size - b * (1 - test_size)) ** 2\n",
    "    return similarity**0.5\n",
    "\n",
    "\n",
    "def plt_value_counts(ax, dataset, tile=None):\n",
    "    counts = dataset.value_counts(sort=False).sort_index()\n",
    "    counts.plot(kind=\"bar\", ax=ax)\n",
    "    if tile:\n",
    "        ax.set_title(tile)\n",
    "\n",
    "\n",
    "def plt_group_split(dataset: pd.DataFrame, test_size: float, random_states: List[int], top_states: int = None):\n",
    "    splits = []\n",
    "    for random_state in tqdm(random_states):\n",
    "        tr, val = group_split_label(\n",
    "            dataset,\n",
    "            test_size=test_size,\n",
    "            groups=dataset[\"Patient_num\"],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        similarity = get_similarity(tr.Brain_plane, val.Brain_plane, test_size)\n",
    "        if similarity >= 0:\n",
    "            splits.append((similarity, tr, val, random_state))\n",
    "\n",
    "    splits.sort(key=lambda e: (e[0], e[3]))\n",
    "    nrows = top_states if top_states else len(splits)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=2,\n",
    "        sharex=\"all\",\n",
    "        squeeze=False,\n",
    "        figsize=(20, 3 * nrows),\n",
    "    )\n",
    "    fig.suptitle(f\"Test size {test_size}\")\n",
    "    for i, (similarity, tr, val, random_state) in enumerate(splits[:nrows]):\n",
    "        plt_value_counts(axes[i, 0], tr.Brain_plane, tile=f\"Seed {random_state}\")\n",
    "        plt_value_counts(axes[i, 1], val.Brain_plane, tile=f\"Similarity {similarity}\")\n",
    "\n",
    "    plt.show()\n",
    "    print([random_state for (similarity, tr, val, random_state) in splits[:nrows]])\n",
    "\n",
    "\n",
    "plt_group_split(\n",
    "    train.img_labels,\n",
    "    test_size=0.2,\n",
    "    random_states=list(range(10000)),\n",
    "    top_states=10,\n",
    ")  # 564, 3097, 1683, 4951, 5724, 8910, 9486, 7023, 5907, 9759\n",
    "# plt_group_split(\n",
    "#     train.img_labels,\n",
    "#     test_size=0.15,\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )  # 943, 9787, 4935, 6588, 6893, 697, 6347, 5785, 4, 7765\n",
    "# plt_group_split(\n",
    "#     train.img_labels,\n",
    "#     test_size=0.1,\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )  # 2251, 3084, 9456, 8902, 1208, 9959, 2696, 2086, 4063, 9126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.img_labels[train.img_labels.Brain_plane == \"Other\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
