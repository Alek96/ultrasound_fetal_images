{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Callable, Iterable, Iterator, Sequence\n",
    "from math import ceil, sqrt\n",
    "from typing import List, Literal, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rootutils\n",
    "import torch\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchvision.transforms.v2.functional as TF\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import FetalBrainPlanesDataset\n",
    "from src.data.components.transforms import RandomPercentCrop\n",
    "from src.data.utils.utils import show_pytorch_images\n",
    "\n",
    "database_dir = root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = pd.read_csv(f\"{database_dir}/FETAL_PLANES/FETAL_PLANES_DB_data.csv\", sep=\";\")\n",
    "img_labels\n",
    "# 12400 rows Ã— 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_labels[\"9\"]=[row[\"Brain_plane\"] if row[\"Plane\"] == \"Fetal brain\" else row[\"Plane\"] for row in img_labels]\n",
    "\n",
    "train_labels = img_labels[img_labels[\"Train \"] == 1]\n",
    "all_classes = train_labels[\"Plane\"] + \".\" + train_labels[\"Brain_plane\"]\n",
    "\n",
    "counts = all_classes.value_counts(sort=False).sort_index()\n",
    "\n",
    "classes = np.unique(all_classes)\n",
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=classes, y=all_classes)\n",
    "\n",
    "pd.DataFrame({\"Count\": counts[classes], \"Weight\": class_weight})\n",
    "\n",
    "\n",
    "# Fetal brain.Other\t77\t10.287157\n",
    "# Fetal brain.Trans-cerebellum\t375\t2.112296\n",
    "# Fetal brain.Trans-thalamic\t873\t0.907344\n",
    "# Fetal brain.Trans-ventricular\t295\t2.685122\n",
    "\n",
    "# Fetal abdomen.Not A Brain\t353\t2.243941\n",
    "# Fetal femur.Not A Brain\t516\t1.535099\n",
    "# Fetal thorax.Not A Brain\t1058\t0.748687\n",
    "# Maternal cervix.Not A Brain\t981\t0.807453\n",
    "# Other.Not A Brain\t2601\t0.304541\n",
    "# 1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_plane = img_labels[\"Brain_plane\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "\n",
    "classes = np.unique(brain_plane)\n",
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=classes, y=brain_plane)\n",
    "\n",
    "pd.DataFrame({\"Count\": counts[classes], \"Weight\": class_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 143 * 0.2 = 115 | 28\n",
    "# 115 * 0.2 =  92 | 23 - 64% 16% 20%\n",
    "\n",
    "# (140 - a) * b = c\n",
    "# 140 * 0.2 = a 28\n",
    "# 140 * 0.1 = c 14\n",
    "# b = c / (140 - a) = 0.125\n",
    "\n",
    "brain_plane = img_labels[img_labels[\"Train \"] == 1][\"Brain_plane\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "\n",
    "classes = np.unique(brain_plane)\n",
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=classes, y=brain_plane)\n",
    "\n",
    "pd.DataFrame({\"Count\": counts[classes], \"Weight\": class_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = img_labels[img_labels[\"Plane\"] == \"Fetal brain\"]\n",
    "img_labels = img_labels[[\"Image_name\", \"Patient_num\", \"Brain_plane\", \"Train \"]]\n",
    "img_labels = img_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "brain_plane = img_labels[\"Brain_plane\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "counts.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    squeeze=False,\n",
    "    sharex=\"all\",\n",
    "    sharey=\"all\",\n",
    "    figsize=(12, 4),\n",
    ")\n",
    "\n",
    "brain_plane = img_labels[img_labels[\"Train \"] == 1][\"Brain_plane\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "counts.plot(kind=\"bar\", ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Train\")\n",
    "\n",
    "brain_plane = img_labels[img_labels[\"Train \"] == 0][\"Brain_plane\"]\n",
    "counts = brain_plane.value_counts(sort=False).sort_index()\n",
    "counts.plot(kind=\"bar\", ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Test\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_group_split(\n",
    "#     img_labels,\n",
    "#     test_size=0.1,  # 0.125 - 10%  0.25 - 20%\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )\n",
    "\n",
    "# 0.2: [435, 3078, 3462, 9261, 9018, 1386, 1216, 8400, 157, 1631]\n",
    "# 0.1: [1631, 9018, 5423, 2091, 7735, 9828, 2526, 3683, 6712, 1849]\n",
    "\n",
    "# 0.1: [8190, 2749, 6106, 8394, 9592, 1585, 990, 2520, 8838, 6802]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import group_split\n",
    "\n",
    "\n",
    "def get_class_num(dataset: Dataset) -> Sequence[int]:\n",
    "    classes = torch.tensor([FetalBrainPlanesDataset.labels.index(dataset[i, 1]) for i in range(len(dataset))])\n",
    "    classes_indices = [torch.nonzero(classes == class_id).flatten() for class_id in torch.arange(5)]\n",
    "    classes_num_samples = [len(indices) for indices in classes_indices]\n",
    "    return classes_num_samples\n",
    "\n",
    "\n",
    "data_all = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    subset=\"all\",\n",
    ")\n",
    "data_train, data_test = group_split(\n",
    "    dataset=data_all,\n",
    "    test_size=0.1,\n",
    "    groups=data_all.img_labels[\"Patient_num\"],\n",
    "    random_state=6106,  # 0.1: [8190, 2749, 6106, 8394, 9592, 1585, 990, 2520, 8838, 6802]\n",
    ")\n",
    "\n",
    "print(len(data_all))\n",
    "print(get_class_num(data_all))\n",
    "\n",
    "print(len(data_test), len(data_test) / len(data_all))\n",
    "print(get_class_num(data_test))\n",
    "\n",
    "print(len(data_train), len(data_train) / len(data_all))\n",
    "print(get_class_num(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = data_all.img_labels.iloc[data_train.indices].reset_index(drop=True)\n",
    "# train_idx = train_idx[train_idx[\"Brain_plane\"] != \"Not A Brain\"]\n",
    "train_idx = train_idx.reset_index(drop=True)\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_group_split(\n",
    "#     train_idx,\n",
    "#     test_size=0.114,  # 0.125 - 10%  0.25 - 20%\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )\n",
    "\n",
    "# 0.125: [1106, 6652, 9111, 4965, 4161, 98, 1985, 9598, 3151, 8322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    subset=\"all\",\n",
    ")\n",
    "data_train, data_test = group_split(\n",
    "    dataset=data_all,\n",
    "    test_size=0.1,\n",
    "    groups=data_all.img_labels[\"Patient_num\"],\n",
    "    random_state=6106,  # 0.1: [8190, 2749, 6106, 8394, 9592, 1585, 990, 2520, 8838, 6802]\n",
    ")\n",
    "\n",
    "data_train, data_val = group_split(\n",
    "    dataset=data_train,\n",
    "    test_size=0.114,\n",
    "    groups=data_all.img_labels.iloc[data_train.indices].reset_index(drop=True)[\"Patient_num\"],\n",
    "    random_state=6277,  # [7539, 6277, 2613, 6652, 2769, 653, 1084, 3368, 9111, 9101]\n",
    ")\n",
    "\n",
    "print(len(data_test), len(data_test) / len(data_all))\n",
    "print(get_class_num(data_test))\n",
    "\n",
    "print(len(data_val), len(data_val) / len(data_all))\n",
    "print(get_class_num(data_val))\n",
    "\n",
    "print(len(data_train), len(data_train) / len(data_all))\n",
    "print(get_class_num(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetalBrainPlanesDataset(Dataset):\n",
    "    labels = [\n",
    "        \"Trans-ventricular\",\n",
    "        \"Trans-thalamic\",\n",
    "        \"Trans-cerebellum\",\n",
    "        \"Other\",\n",
    "        \"Not A Brain\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        data_name: str = \"FETAL_PLANES\",\n",
    "        train: bool = True,\n",
    "        transform: Callable | None = None,\n",
    "        target_transform: Callable | None = None,\n",
    "    ):\n",
    "        self.dataset_dir = f\"{data_dir}/{data_name}\"\n",
    "        self.img_labels = self.load_img_labels(train)\n",
    "        self.img_dir = f\"{self.dataset_dir}/Images\"\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def load_img_labels(self, train: bool):\n",
    "        img_labels = pd.read_csv(f\"{self.dataset_dir}/FETAL_PLANES_DB_data.csv\", sep=\";\")\n",
    "        img_labels = img_labels[img_labels[\"Train \"] == (1 if train else 0)]\n",
    "        img_labels = img_labels[[\"Image_name\", \"Patient_num\", \"Brain_plane\"]]\n",
    "        return img_labels.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            idx, sub_idx = idx\n",
    "            if sub_idx == 0:\n",
    "                return self.get_image(idx)\n",
    "            elif sub_idx == 1:\n",
    "                return self.get_label(idx)\n",
    "\n",
    "        return self.get_image(idx), self.get_label(idx)\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.Image_name[idx] + \".png\")\n",
    "        image = read_image(img_path)\n",
    "        if image.shape[0] == 4:\n",
    "            image = image[:3, :, :]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "\n",
    "        label = self.img_labels.Brain_plane[idx]\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset(\n",
    "    [\n",
    "        FetalBrainPlanesDataset(data_dir=database_dir, subset=\"train\"),\n",
    "        # FetalBrainPlanesDataset(data_dir=database_dir, subset=\"test\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pytorch_images(\n",
    "    [dataset[i] for i in np.random.permutation(len(dataset))[:25]],\n",
    "    tick_labels=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=iter(tqdm(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame(data=[(i.shape[0], i.shape[1], i.shape[2]) for i in df[0]])\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_shape.mean()\n",
    "median = df_shape.median()\n",
    "\n",
    "axs = df_shape.hist(column=[1, 2], bins=100, figsize=(20, 5))\n",
    "\n",
    "axs[0][0].axvline(mean[1], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 572.415\n",
    "axs[0][1].axvline(mean[2], color=\"r\", linestyle=\"dashed\", linewidth=2)  # 661.0\n",
    "axs[0][0].axvline(median[1], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 857.255\n",
    "axs[0][1].axvline(median[2], color=\"b\", linestyle=\"dashed\", linewidth=2)  # 959.0\n",
    "axs[0][0].legend([f\"mean {mean[1]}\", f\"median {median[1]}\"], loc=\"upper left\")\n",
    "axs[0][1].legend([f\"mean {mean[2]}\", f\"median {median[2]}\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = median[2] / median[1]\n",
    "\n",
    "\n",
    "def print_resolution(width):\n",
    "    height = width / scale\n",
    "    print(f\"{height:.2f} / {width}\")\n",
    "\n",
    "\n",
    "print_resolution(80)  # 55 / 80\n",
    "print_resolution(100)  # 70 / 100\n",
    "print_resolution(150)  # 100 / 150\n",
    "print_resolution(240)  # 165 / 240\n",
    "\n",
    "print_resolution(300)  # 205 / 300\n",
    "print_resolution(400)  # 275 / 400\n",
    "print_resolution(500)  # 345 / 500\n",
    "print_resolution(600)  # 415 / 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    (\n",
    "        channels_sum,\n",
    "        channels_sqrd_sum,\n",
    "    ) = (\n",
    "        0,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    for data, _ in tqdm(dataset):\n",
    "        channels_sum += torch.mean(data, dim=[1, 2])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[1, 2])\n",
    "\n",
    "    mean = channels_sum / len(dataset)\n",
    "    std = (channels_sqrd_sum / len(dataset) - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def find_mean_std(height, width):\n",
    "    train = FetalBrainPlanesDataset(\n",
    "        data_dir=database_dir,\n",
    "        subset=\"train\",\n",
    "        transform=torch.nn.Sequential(\n",
    "            T.Grayscale(),\n",
    "            T.Resize((height, width)),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    mean, std = get_mean_std(train)\n",
    "    print(f\"For {height} / {width} mean is {mean.item():.2f} std is {std.item():.2f}\")\n",
    "\n",
    "\n",
    "# print(mean.item())  # 0.16958117485046387, 0.16958120197261892\n",
    "# print(std.item())  # 0.1906554251909256,  0.19065533816416103\n",
    "find_mean_std(55, 80)  # 0.17 / 0.19\n",
    "find_mean_std(165, 240)  # 0.17 / 0.19\n",
    "find_mean_std(415, 600)  # 0.17 / 0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    subset=\"train\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        # RandomPercentCrop(max_percent=20),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        # T.RandomHorizontalFlip(p=0.5),\n",
    "        # T.RandomAffine(degrees=15, fill=255),\n",
    "        # T.RandomAffine(degrees=0, translate=(0.1, 0.1), fill=255),\n",
    "        # T.RandomAffine(degrees=0, scale=(1.0, 1.2), fill=255),\n",
    "        # T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(1.0, 1.2), fill=255),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        # T.Normalize(mean=0.17, std=0.19),\n",
    "    ),\n",
    ")\n",
    "\n",
    "show_pytorch_images([train[i] for i in np.random.permutation(len(train))][:49]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FetalBrainPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    subset=\"train\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240)),\n",
    "        T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "        # T.RandAugment(),\n",
    "        # T.TrivialAugmentWide(),\n",
    "        # T.AugMix(),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "show_pytorch_images([train[i] for i in np.random.permutation(len(train))][:49]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_split_label(\n",
    "    dataset: pd.DataFrame, test_size: float, groups, random_state: int = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=random_state)\n",
    "    split = splitter.split(dataset, groups=groups)\n",
    "    train_idx, test_idx = next(split)\n",
    "    return dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
    "\n",
    "\n",
    "def get_similarity(train, test, test_size):\n",
    "    similarity = 0\n",
    "    train_count = train.value_counts(sort=False).sort_index()\n",
    "    test_count = test.value_counts(sort=False).sort_index()\n",
    "\n",
    "    if train_count.index.tolist() != test_count.index.tolist():\n",
    "        return -1\n",
    "\n",
    "    for a, b in zip(train_count, test_count):\n",
    "        similarity += (a * test_size - b * (1 - test_size)) ** 2\n",
    "    return similarity**0.5\n",
    "\n",
    "\n",
    "def plt_value_counts(ax, dataset, tile=None):\n",
    "    counts = dataset.value_counts(sort=False).sort_index()\n",
    "    counts.plot(kind=\"bar\", ax=ax)\n",
    "    if tile:\n",
    "        ax.set_title(tile)\n",
    "\n",
    "\n",
    "def plt_group_split(dataset: pd.DataFrame, test_size: float, random_states: List[int], top_states: int = None):\n",
    "    splits = []\n",
    "    for random_state in tqdm(random_states):\n",
    "        tr, val = group_split_label(\n",
    "            dataset,\n",
    "            test_size=test_size,\n",
    "            groups=dataset[\"Patient_num\"],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        similarity = get_similarity(tr.Brain_plane, val.Brain_plane, test_size)\n",
    "        if similarity >= 0:\n",
    "            splits.append((similarity, tr, val, random_state))\n",
    "\n",
    "    splits.sort(key=lambda e: (e[0], e[3]))\n",
    "    nrows = top_states if top_states else len(splits)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=2,\n",
    "        sharex=\"all\",\n",
    "        squeeze=False,\n",
    "        figsize=(20, 3 * nrows),\n",
    "    )\n",
    "    fig.suptitle(f\"Test size {test_size}\")\n",
    "    for i, (similarity, tr, val, random_state) in enumerate(splits[:nrows]):\n",
    "        plt_value_counts(axes[i, 0], tr.Brain_plane, tile=f\"Seed {random_state}\")\n",
    "        plt_value_counts(axes[i, 1], val.Brain_plane, tile=f\"Similarity {similarity}\")\n",
    "\n",
    "    plt.show()\n",
    "    print([random_state for (similarity, tr, val, random_state) in splits[:nrows]])\n",
    "\n",
    "\n",
    "plt_group_split(\n",
    "    train.img_labels,\n",
    "    test_size=0.2,\n",
    "    random_states=list(range(10000)),\n",
    "    top_states=10,\n",
    ")  # 564, 3097, 1683, 4951, 5724, 8910, 9486, 7023, 5907, 9759\n",
    "# plt_group_split(\n",
    "#     train.img_labels,\n",
    "#     test_size=0.15,\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )  # 943, 9787, 4935, 6588, 6893, 697, 6347, 5785, 4, 7765\n",
    "# plt_group_split(\n",
    "#     train.img_labels,\n",
    "#     test_size=0.1,\n",
    "#     random_states=list(range(10000)),\n",
    "#     top_states=10,\n",
    "# )  # 2251, 3084, 9456, 8902, 1208, 9959, 2696, 2086, 4063, 9126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.img_labels[train.img_labels.Brain_plane == \"Other\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
