{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=\".\",\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision.transforms import ConvertImageDtype, Grayscale, Resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datamodules.fetal_planes import FetalPlanesDataset\n",
    "\n",
    "database_dir = root / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset(\n",
    "    [\n",
    "        FetalPlanesDataset(data_dir=database_dir, train=True),\n",
    "        FetalPlanesDataset(data_dir=database_dir, train=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs, tick_labels: bool = True):\n",
    "    n = ceil(sqrt(len(imgs)))\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=n, nrows=n, squeeze=False, figsize=(20, 15))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i * n + j >= len(imgs):\n",
    "                continue\n",
    "\n",
    "            img, label = imgs[i * n + j]\n",
    "            img = img.detach()\n",
    "            img = F.to_pil_image(img)\n",
    "            img = F.to_grayscale(img)\n",
    "            axes[i, j].imshow(np.asarray(img), cmap=\"binary\")\n",
    "            axes[i, j].set_xlabel(label)\n",
    "            if not tick_labels:\n",
    "                axes[i, j].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show([dataset[i] for i in np.random.permutation(len(dataset))[:25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=iter(tqdm(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame(data=[(i.shape[0], i.shape[1], i.shape[2]) for i in df[0]])\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_shape.mean()\n",
    "median = df_shape.median()\n",
    "\n",
    "axs = df_shape.hist(column=[1, 2], bins=100, figsize=(20, 5))\n",
    "\n",
    "axs[0][0].axvline(mean[1], color=\"r\", linestyle=\"dashed\", linewidth=2)\n",
    "axs[0][1].axvline(mean[2], color=\"r\", linestyle=\"dashed\", linewidth=2)\n",
    "axs[0][0].axvline(median[1], color=\"b\", linestyle=\"dashed\", linewidth=2)\n",
    "axs[0][1].axvline(median[2], color=\"b\", linestyle=\"dashed\", linewidth=2)\n",
    "axs[0][0].legend([f\"mean {mean[1]}\", f\"median {median[1]}\"], loc=\"upper left\")\n",
    "axs[0][1].legend([f\"mean {mean[2]}\", f\"median {median[2]}\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = median[2] / median[1]\n",
    "80 / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, = (\n",
    "        0,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    for data, _ in tqdm(dataset):\n",
    "        channels_sum += torch.mean(data, dim=[1, 2])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[1, 2])\n",
    "\n",
    "    mean = channels_sum / len(dataset)\n",
    "    std = (channels_sqrd_sum / len(dataset) - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "train = FetalPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        Grayscale(), ConvertImageDtype(torch.float32), Resize((165, 240))\n",
    "    ),\n",
    ")\n",
    "\n",
    "mean, std = get_mean_std(train)\n",
    "print(mean)  # 0.16958117485046387, 0.16958120197261892\n",
    "print(std)  # 0.1906554251909256,  0.19065533816416103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FetalPlanesDataset(\n",
    "    data_dir=database_dir,\n",
    "    train=True,\n",
    "    transform=torch.nn.Sequential(\n",
    "        Grayscale(),\n",
    "        ConvertImageDtype(torch.float32),\n",
    "        Resize((55, 80)),  # (55, 80), (70, 100), (100, 150), (170, 250)\n",
    "        # Normalize(mean=mean, std=std)\n",
    "    ),\n",
    ")\n",
    "\n",
    "show([train[i] for i in np.random.permutation(len(train))[:25]], tick_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_split_label(\n",
    "    dataset: pd.DataFrame, test_size: float, groups, random_state: int = None\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=random_state)\n",
    "    split = splitter.split(dataset, groups=groups)\n",
    "    train_idx, test_idx = next(split)\n",
    "    return dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
    "\n",
    "\n",
    "def get_similarity(train, test, test_size):\n",
    "    similarity = 0\n",
    "    train_count = train.value_counts(sort=False)\n",
    "    test_count = test.value_counts(sort=False)\n",
    "    for (a, b) in zip(train_count, test_count):\n",
    "        similarity += (a * test_size - b * (1 - test_size)) ** 2\n",
    "    return similarity**0.5\n",
    "\n",
    "\n",
    "def plt_value_counts(ax, dataset, tile=None):\n",
    "    counts = dataset.value_counts(sort=False)\n",
    "    counts.plot(kind=\"bar\", ax=ax)\n",
    "    print(counts)\n",
    "    if tile:\n",
    "        ax.set_title(tile)\n",
    "\n",
    "\n",
    "def plt_group_split(\n",
    "    dataset: pd.DataFrame, test_size: float, random_states: List[int], top_states: int = None\n",
    "):\n",
    "    splits = []\n",
    "    for random_state in random_states:\n",
    "        tr, val = group_split_label(\n",
    "            dataset, test_size=test_size, groups=dataset[\"Patient_num\"], random_state=random_state\n",
    "        )\n",
    "\n",
    "        similarity = get_similarity(tr.Plane, val.Plane, test_size)\n",
    "        splits.append((similarity, tr, val, random_state))\n",
    "\n",
    "    splits.sort()\n",
    "    nrows = top_states if top_states else len(random_states)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows, ncols=2, sharex=\"all\", squeeze=False, figsize=(20, 3 * nrows)\n",
    "    )\n",
    "    fig.suptitle(f\"Test size {test_size}\")\n",
    "    for (i, (similarity, tr, val, random_state)) in enumerate(splits[:nrows]):\n",
    "        plt_value_counts(axes[i, 0], tr.Plane, tile=f\"Seed {random_state}\")\n",
    "        plt_value_counts(axes[i, 1], val.Plane, tile=f\"Similarity {similarity}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt_group_split(\n",
    "    train.img_labels, test_size=0.2, random_states=list(range(100)), top_states=3\n",
    ")  # 79\n",
    "plt_group_split(\n",
    "    train.img_labels, test_size=0.15, random_states=list(range(100)), top_states=3\n",
    ")  # 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodules.utils import group_split\n",
    "\n",
    "print(len(train))\n",
    "print(\"\")\n",
    "\n",
    "tr, val = group_split(\n",
    "    train, test_size=0.2, groups=train.img_labels[\"Patient_num\"], random_state=79\n",
    ")\n",
    "\n",
    "print(len(tr))\n",
    "print(len(val))\n",
    "print(\"\")\n",
    "\n",
    "tr, val = group_split(\n",
    "    train, test_size=0.15, groups=train.img_labels[\"Patient_num\"], random_state=34\n",
    ")\n",
    "\n",
    "print(len(tr))\n",
    "print(len(val))\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
