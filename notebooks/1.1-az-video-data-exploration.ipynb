{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=\".\",\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.fetal_module import FetalLitModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = str(\n",
    "    root / \"logs\" / \"train\" / \"runs\" / \"2023-01-08_19-53-10\" / \"checkpoints\" / \"epoch_019.ckpt\"\n",
    ")\n",
    "model = FetalLitModule.load_from_checkpoint(checkpoint_file)\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Grayscale(),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "        T.Resize((55, 80)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "labels = [\n",
    "    \"Other\",\n",
    "    \"Maternal cervix\",\n",
    "    \"Fetal abdomen\",\n",
    "    \"Fetal brain\",\n",
    "    \"Fetal femur\",\n",
    "    \"Fetal thorax\",\n",
    "]\n",
    "\n",
    "\n",
    "def label_videos(path: pathlib.Path):\n",
    "    videos_path = path / \"videos\"\n",
    "    images_path = path / \"labeled\"\n",
    "    videos = len(list(videos_path.iterdir()))\n",
    "    for i, video_path in enumerate(videos_path.iterdir()):\n",
    "        label_video(video_path, images_path, i + 1, videos)\n",
    "\n",
    "\n",
    "def frame_iter(capture, description):\n",
    "    def iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "\n",
    "    return tqdm(\n",
    "        iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "    )\n",
    "\n",
    "\n",
    "def label_video(video_path: pathlib.Path, images_path: pathlib.Path, it: int, videos: int):\n",
    "    if not video_path.exists():\n",
    "        print(f\"path {video_path} not exist\")\n",
    "\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    for i, frame in enumerate(frame_iter(vidcap, f\"label video {it}/{videos}\")):\n",
    "        label = label_frame(frame)\n",
    "        img_path = images_path / video_path.stem / label / (\"frame%d.jpg\" % i)\n",
    "        if not img_path.parent.exists():\n",
    "            img_path.parent.mkdir(parents=True)\n",
    "        cv2.imwrite(str(img_path), frame)\n",
    "\n",
    "    count_images(images_path / video_path.stem)\n",
    "\n",
    "\n",
    "def label_frame(frame):\n",
    "    with torch.no_grad():\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = transforms(frame)\n",
    "        frame = frame.unsqueeze(0)\n",
    "        y = model(frame)\n",
    "        pred = y.max(1).indices[0]\n",
    "        return labels[pred]\n",
    "\n",
    "\n",
    "def count_images(images_path: pathlib.Path):\n",
    "    count = {}\n",
    "    for label in labels:\n",
    "        count[label] = 0\n",
    "    for label_dir in images_path.iterdir():\n",
    "        count[label_dir.name] = len(list(label_dir.iterdir()))\n",
    "    print(count)\n",
    "\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS\"\n",
    "label_videos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Other\",\n",
    "    \"Maternal cervix\",\n",
    "    \"Fetal abdomen\",\n",
    "    \"Fetal brain\",\n",
    "    \"Fetal femur\",\n",
    "    \"Fetal thorax\",\n",
    "]\n",
    "\n",
    "\n",
    "def count_all_images(images_path: pathlib.Path):\n",
    "    count = {}\n",
    "    for label in labels:\n",
    "        count[label] = 0\n",
    "    for video_dir in images_path.iterdir():\n",
    "        for label_dir in video_dir.iterdir():\n",
    "            count[label_dir.name] += len(list(label_dir.iterdir()))\n",
    "    return count\n",
    "\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS\" / \"labeled\"\n",
    "images = count_all_images(path)\n",
    "for key, item in images.items():\n",
    "    print(f\"{key}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USVideosDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        max_images: int,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ):\n",
    "        data_dir = Path(data_dir) / \"US_VIDEOS\" / \"labeled\"\n",
    "        images = self.find_images(data_dir)\n",
    "        self.items = []\n",
    "        for key, item in images.items():\n",
    "            idxs = np.random.permutation(len(item))[:max_images]\n",
    "            self.items.extend([(str(item[idx]), key) for idx in idxs])\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    @staticmethod\n",
    "    def find_images(images_path: pathlib.Path):\n",
    "        images = {}\n",
    "        for video_dir in images_path.iterdir():\n",
    "            for label_dir in video_dir.iterdir():\n",
    "                label = label_dir.name\n",
    "                if label not in images:\n",
    "                    images[label] = []\n",
    "                images[label].extend(label_dir.iterdir())\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise IndexError(\"list index out of range\")\n",
    "\n",
    "        img_path, label = self.items[idx]\n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "data_dir = root / \"data\"\n",
    "dataset = USVideosDataset(\n",
    "    data_dir=str(data_dir),\n",
    "    max_images=1000,\n",
    ")\n",
    "print(len(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
