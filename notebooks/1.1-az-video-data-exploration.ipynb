{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import pyrootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchvision.io import read_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "root = pyrootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import FetalBrainPlanesDataset, USVideosDataset\n",
    "from src.data.components.transforms import Affine, HorizontalFlip\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "\n",
    "path = root / \"data\" / \"US_VIDEOS_2\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(path / \"selected\", ignore_errors=True)\n",
    "shutil.rmtree(path / \"labeled\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-02-21_18-51-47\"\n",
    "checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-02-23_10-41-08\"\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_video(video_path: Path):\n",
    "    y_hats = []\n",
    "    all_logits = []\n",
    "    base_dense_logits = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    for frame in _frame_iter(vidcap, \"Label frames\"):\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frame = frame.to(model.device)\n",
    "        frames = torch.stack([transform(frame) for transform in transforms])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dense_logits, logits = model(frames)\n",
    "            y_hat = F.softmax(logits, dim=1)\n",
    "            y_hats.append(y_hat)\n",
    "            all_logits.append(logits)\n",
    "            base_dense_logits.append(dense_logits[0])\n",
    "\n",
    "    return torch.stack(base_dense_logits, dim=0), torch.stack(all_logits, dim=1), torch.stack(y_hats, dim=1)\n",
    "\n",
    "\n",
    "def _frame_iter(capture, description):\n",
    "    def iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "\n",
    "    return tqdm(\n",
    "        iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "rotate_degrees = [0, -15, 15]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "\n",
    "transforms = [\n",
    "    T.Compose(\n",
    "        [\n",
    "            T.Grayscale(),\n",
    "            T.Resize((165, 240)),\n",
    "            HorizontalFlip(flip=horizontal_flip),\n",
    "            Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "        ]\n",
    "    )\n",
    "    for horizontal_flip, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips, rotate_degrees, translates, scales\n",
    "    )\n",
    "]\n",
    "\n",
    "video_path = sorted((path / \"videos\").iterdir())[0]\n",
    "_, logits, y_hats = label_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probabilities(y_hats, ax):\n",
    "    x = list(range(y_hats.shape[0]))\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x, y_hats[:, i], label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_best_probabilities(y_hats, ax):\n",
    "    x = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], 0)).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        x[best].append(i)\n",
    "        y[best].append(y_hat[best])\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=2, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def is_stable(y, i):\n",
    "    min_i = max(0, i - window)\n",
    "    max_i = min(i + window, len(y) - 1)\n",
    "\n",
    "    if min_i > i - window or max_i < i + window:\n",
    "        return False\n",
    "\n",
    "    for j in range(min_i, max_i + 1):\n",
    "        if y[j] == 0.0:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def plot_filtered_probabilities(y_hats, ax):\n",
    "    x = torch.arange(0, y_hats.shape[0]).int().repeat(y_hats.shape[1], 1).tolist()\n",
    "    y = torch.zeros((y_hats.shape[1], y_hats.shape[0])).tolist()\n",
    "\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        best = torch.argmax(y_hat)\n",
    "        y[best][i] = y_hat[best]\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        to_delete = []\n",
    "\n",
    "        for j in range(len(y[i])):\n",
    "            if not is_stable(y[i], j):\n",
    "                to_delete.append(j)\n",
    "\n",
    "        to_delete.sort(reverse=True)\n",
    "        for j in to_delete:\n",
    "            x[i].pop(j)\n",
    "            y[i].pop(j)\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        ax.plot(x[i], y[i], \"o\", markersize=2, label=label)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "label_def = FetalBrainPlanesDataset.labels\n",
    "\n",
    "window = 3\n",
    "temperature = 2.0\n",
    "y_hats = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "ncols = 3\n",
    "nrows = len(y_hats)\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=ncols,\n",
    "    nrows=nrows,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    squeeze=False,\n",
    "    tight_layout=True,\n",
    "    figsize=(10 * ncols, 5 * nrows),\n",
    ")\n",
    "\n",
    "for i, y_hat in enumerate(y_hats):\n",
    "    plot_probabilities(y_hat, axes[i, 0])\n",
    "    plot_best_probabilities(y_hat, axes[i, 1])\n",
    "    plot_filtered_probabilities(y_hat, axes[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_ = torch.tensor(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [2.0, 3.0, 4.0], [3.0, 4.0, 5.0], [1.0, 3.0, 2.0], [1.0, 3.0, 2.0]],\n",
    "        [[1.0, 4.0, 2.0], [2.0, 4.0, 3.0], [3.0, 4.0, 5.0], [1.0, 3.0, 2.0], [1.0, 3.0, 2.0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pred = torch.argmax(y_hats_, dim=2)\n",
    "print(pred)\n",
    "\n",
    "mask = F.one_hot(pred) == 0\n",
    "y_hats_ = torch.masked_fill(y_hats_, mask, 0.0)\n",
    "print(y_hats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        min_j = max(0, j - window)\n",
    "        max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "        if not torch.all(pred[i, min_j:max_j] == pred[i, j]):\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        if torch.sum(pred[i, j - window : j + window + 1] == pred[i, j]) < 1 + 2 * window:\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats__ = torch.mean(y_hats_, dim=0)\n",
    "print(y_hats__.shape)\n",
    "print(y_hats__)\n",
    "\n",
    "plates = y_hats__[:, :2]\n",
    "other = y_hats__[:, 2:]\n",
    "\n",
    "quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "print(quality)\n",
    "\n",
    "quality = quality / torch.sum(plates > 0, dim=1)\n",
    "zaro_mask = torch.eq(quality > 0, False)\n",
    "torch.masked_fill(quality, zaro_mask, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 3.0\n",
    "y_hats_ = F.softmax(logits / temperature, dim=2)\n",
    "\n",
    "# print(y_hats_.shape)\n",
    "# y_hats_ = y_hats.clone()\n",
    "\n",
    "pred = torch.argmax(y_hats_, dim=2)\n",
    "print(pred.shape)\n",
    "pred_mask = F.one_hot(pred, num_classes=y_hats_.shape[2]) == 0\n",
    "print(pred_mask.shape)\n",
    "y_hats_.masked_fill_(pred_mask, 0.0)\n",
    "\n",
    "window = 3\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        min_j = max(0, j - window)\n",
    "        max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "        if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "            y_hats_[i, j, pred[i, j]] = 0\n",
    "\n",
    "y_hats_ = torch.mean(y_hats_, dim=0)\n",
    "plates = y_hats_[:, :3]\n",
    "other = y_hats_[:, 3:]\n",
    "quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "quality = quality / torch.sum(plates > 0, dim=1)\n",
    "zaro_mask = torch.eq(quality > 0, False)\n",
    "quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, squeeze=False, tight_layout=True, figsize=(10, 5))\n",
    "axes[0, 0].plot(range(len(quality)), quality)\n",
    "axes[0, 0].set_xlim(left=0, right=len(quality))\n",
    "axes[0, 0].set_ylim(bottom=0, top=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-02-21_18-51-47\"\n",
    "# checkpoint_file = root / \"logs\" / \"train\" / \"runs\" / \"2023-02-22_12-35-41\"\n",
    "\n",
    "checkpoint = sorted(checkpoint_file.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path: Path):\n",
    "    videos_path = path / \"videos\"\n",
    "    data_path = path / \"data\"\n",
    "    plots_path = path / \"plots\"\n",
    "    shutil.rmtree(data_path, ignore_errors=True)\n",
    "    shutil.rmtree(plots_path, ignore_errors=True)\n",
    "\n",
    "    videos = list(videos_path.iterdir())\n",
    "    for i, video_path in enumerate(tqdm(videos, desc=\"Label videos\", position=1)):\n",
    "        dense_logits, y_hats = label_video(video_path)\n",
    "        y_hats, quality = calculate_quality(y_hats)\n",
    "        save_processed_video(data_path, video_path.stem, dense_logits, quality)\n",
    "        save_quality_plot(plots_path, video_path.stem, y_hats, quality)\n",
    "\n",
    "\n",
    "def label_video(video_path: Path):\n",
    "    y_hats = []\n",
    "    base_dense_logits = []\n",
    "\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    for frame in frame_iter(vidcap, \"Label frames\"):\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frame = frame.to(model.device)\n",
    "        frames = torch.stack([transform(frame) for transform in transforms])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dense_logits, logits = model(frames)\n",
    "            y_hat = F.softmax(logits, dim=1)\n",
    "            y_hats.append(y_hat)\n",
    "            base_dense_logits.append(dense_logits[0])\n",
    "\n",
    "    return torch.stack(base_dense_logits, dim=0), torch.stack(y_hats, dim=1)\n",
    "\n",
    "\n",
    "def frame_iter(capture, description):\n",
    "    def iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "\n",
    "    return tqdm(\n",
    "        iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_quality(y_hats: Tensor):\n",
    "    # select highest prediction\n",
    "    pred = torch.argmax(y_hats, dim=2)\n",
    "    pred_mask = F.one_hot(pred, num_classes=y_hats.shape[2]) == 0\n",
    "    y_hats.masked_fill_(pred_mask, 0.0)\n",
    "\n",
    "    # remove predictions that are inconsistent\n",
    "    window = 3\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            min_j = max(0, j - window)\n",
    "            max_j = min(j + window + 1, pred.shape[1])\n",
    "\n",
    "            if not torch.all(torch.eq(pred[i, min_j:max_j], pred[i, j])):\n",
    "                y_hats[i, j, pred[i, j]] = 0\n",
    "\n",
    "    # average of all transformations\n",
    "    y_hats = torch.mean(y_hats, dim=0)\n",
    "\n",
    "    # (sum planes' prediction - sum no planes' prediction) / (number of planes' prediction greater than 0)\n",
    "    plates = y_hats[:, :3]\n",
    "    other = y_hats[:, 3:]\n",
    "    quality = torch.sum(plates, dim=1) - torch.sum(other, dim=1)\n",
    "    quality = quality / torch.sum(plates > 0, dim=1)\n",
    "    zaro_mask = torch.eq(quality > 0, False)\n",
    "    quality.masked_fill_(zaro_mask, 0.0)\n",
    "\n",
    "    return y_hats, quality\n",
    "\n",
    "\n",
    "def save_processed_video(data_path: Path, video: str, dense_logits: Tensor, quality: Tensor):\n",
    "    with open(f\"{data_path}/{video}.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(zip(dense_logits, quality))\n",
    "\n",
    "\n",
    "def save_quality_plot(plots_path: Path, video: str, y_hats: Tensor, quality: Tensor):\n",
    "    fig, axes = plt.subplots(ncols=1, nrows=3, sharex=True, sharey=True, tight_layout=True, figsize=(10, 15))\n",
    "\n",
    "    for i, label in enumerate(label_def):\n",
    "        x, y = extract_nonzero_values(y_hats[:, i])\n",
    "        axes[0].plot(x, y, \"o\", markersize=2, label=label)\n",
    "    axes[1].plot(range(len(quality)), quality, \"o\", color=\"tab:gray\")\n",
    "    axes[2].plot(range(len(quality)), quality, color=\"tab:gray\")\n",
    "\n",
    "    fig.xlim(left=0, right=len(quality))\n",
    "    fig.ylim(bottom=0, top=1)\n",
    "    plt.savefig(f\"{plots_path}/{video}.csv\")\n",
    "\n",
    "\n",
    "def extract_nonzero_values(y_hats):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, y_hat in enumerate(y_hats):\n",
    "        if y_hat > 0:\n",
    "            x.append(i)\n",
    "            y.append(y_hat)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "rotate_degrees = [0, -15, 15]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "\n",
    "transforms = [\n",
    "    T.Compose(\n",
    "        [\n",
    "            T.Grayscale(),\n",
    "            T.Resize((165, 240)),\n",
    "            HorizontalFlip(flip=horizontal_flip),\n",
    "            Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "        ]\n",
    "    )\n",
    "    for horizontal_flip, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips, rotate_degrees, translates, scales\n",
    "    )\n",
    "]\n",
    "\n",
    "y_hats = create_dataset(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
