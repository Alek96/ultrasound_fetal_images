{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchvision.transforms.v2.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchmetrics import Metric\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "# from src.data.components.dataset import FetalPlanesDataset, USVideosDataset\n",
    "# from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "# from src.models.fetal_module import FetalLitModule\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.utils import get_model\n",
    "\n",
    "model = get_model(name=\"efficientnet_v2_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in model.model.named_children():\n",
    "    print(name)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import get_model\n",
    "\n",
    "efficientnet = get_model(name=\"efficientnet_v2_m\", weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in efficientnet.features.named_children():\n",
    "    print(name)\n",
    "\n",
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = get_model(name=\"resnet101\", weights=\"DEFAULT\")\n",
    "\n",
    "for name, layer in resnet.named_children():\n",
    "    print(name)\n",
    "\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    supported_models = [\"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\"]\n",
    "\n",
    "    freez_layers_name = [\n",
    "        \"conv1\",\n",
    "        \"bn1\",\n",
    "        \"layer1\",\n",
    "        \"layer2\",\n",
    "        \"layer3\",\n",
    "        \"layer4\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"resnet18\",\n",
    "        output_size: int = 6,\n",
    "        pretrain: bool = True,\n",
    "        freez_layers: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert name in self.supported_models\n",
    "        self.model = get_model(name=name, weights=\"DEFAULT\" if pretrain else None)\n",
    "\n",
    "        if freez_layers == 0:\n",
    "            # replace input 3 channels with 1 channel\n",
    "            old_conv = self.model.conv1\n",
    "            conv = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                dilation=old_conv.dilation,\n",
    "                groups=old_conv.groups,\n",
    "                bias=old_conv.bias is not None,\n",
    "                padding_mode=old_conv.padding_mode,\n",
    "            )\n",
    "            conv.weight = nn.Parameter(torch.mean(old_conv.weight, dim=1, keepdim=True))\n",
    "            self.model.conv1 = conv\n",
    "\n",
    "        # output\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=self.model.fc.in_features,\n",
    "            out_features=output_size,\n",
    "        )\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "        for layer_name in self.freez_layers_name[:freez_layers]:\n",
    "            freez_model_layers(self.model, layer_name, False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_logits = self.model(x)\n",
    "        return dense_logits, self.classifier(dense_logits)\n",
    "\n",
    "\n",
    "model = ResNet(name=\"resnet101\", freez_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    supported_efficientnet_models = [\"efficientnet_b0\"]\n",
    "    supported_efficientnet_v2_models = [\"efficientnet_v2_s\", \"efficientnet_v2_m\", \"efficientnet_v2_l\"]\n",
    "    supported_models = supported_efficientnet_models + supported_efficientnet_v2_models\n",
    "\n",
    "    freez_layers_name = [\n",
    "        \"features.0\",\n",
    "        \"features.1\",\n",
    "        \"features.2\",\n",
    "        \"features.3\",\n",
    "        \"features.4\",\n",
    "        \"features.5\",\n",
    "        \"features.6\",\n",
    "        \"features.7\",\n",
    "        \"features.8\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"efficientnet_b0\",\n",
    "        output_size: int = 6,\n",
    "        pretrain: bool = True,\n",
    "        freez_layers: int = 0,\n",
    "        dropout: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert name in self.supported_models\n",
    "\n",
    "        get_model_param = {\"name\": name, \"weights\": \"DEFAULT\" if pretrain else None}\n",
    "        if dropout is not None:\n",
    "            get_model_param[\"dropout\"] = dropout\n",
    "        self.model = get_model(**get_model_param)\n",
    "\n",
    "        # input\n",
    "        if freez_layers == 0:\n",
    "            old_conv = self.model.features[0][0]\n",
    "            conv = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                dilation=old_conv.dilation,\n",
    "                groups=old_conv.groups,\n",
    "                bias=old_conv.bias is not None,\n",
    "                padding_mode=old_conv.padding_mode,\n",
    "            )\n",
    "            conv.weight = nn.Parameter(torch.mean(old_conv.weight, dim=1, keepdim=True))\n",
    "            self.model.features[0][0] = conv\n",
    "\n",
    "        # output\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=self.model.classifier[-1].in_features,\n",
    "            out_features=output_size,\n",
    "        )\n",
    "        self.model.classifier = self.model.classifier[:-1]\n",
    "\n",
    "        freez_model_layers(model=self.model, layers_name=self.freez_layers_name[:freez_layers], freez_batch_norm=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_logits = self.model(x)\n",
    "        return dense_logits, self.classifier(dense_logits)\n",
    "\n",
    "\n",
    "model = EfficientNet(name=\"efficientnet_v2_m\", freez_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freez_model_layers(model, layers_name: [str], freez_batch_norm: bool = True):\n",
    "\n",
    "    for layer_name in layers_name:\n",
    "        module = model\n",
    "        for layer in layer_name.split(\".\"):\n",
    "            module = getattr(module, layer)\n",
    "\n",
    "        freez_model_layer(module, freez_batch_norm=freez_batch_norm)\n",
    "\n",
    "\n",
    "batch_norm_classes = [\n",
    "    \"BatchNorm1d\",\n",
    "    \"BatchNorm2d\",\n",
    "    \"BatchNorm3d\",\n",
    "    \"LazyBatchNorm1d\",\n",
    "    \"LazyBatchNorm2d\",\n",
    "    \"LazyBatchNorm3d\",\n",
    "]\n",
    "\n",
    "\n",
    "def freez_model_layer(model, freez_batch_norm: bool = True):\n",
    "    if len(list(model.named_children())) == 0:\n",
    "        if freez_batch_norm or model.__class__.__name__ not in batch_norm_classes:\n",
    "            model.requires_grad_(requires_grad=False)\n",
    "    else:\n",
    "        for layer in model.children():\n",
    "            freez_model_layer(layer, freez_batch_norm)\n",
    "\n",
    "\n",
    "def summary(model, spaces=0):\n",
    "    if len(list(model.named_children())) == 0:\n",
    "        for name, param in model.named_parameters():\n",
    "            space_name = f\"{' ' * spaces}{name}:\"\n",
    "            print(f\"{space_name:<50} {param.requires_grad}\")\n",
    "    else:\n",
    "        for name, layer in model.named_children():\n",
    "            print(f\"{' ' * spaces}{name}: {layer.__class__.__name__}\")\n",
    "            summary(model=layer, spaces=spaces + 2)\n",
    "\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_classes = [\n",
    "    \"BatchNorm1d\",\n",
    "    \"BatchNorm2d\",\n",
    "    \"BatchNorm3d\",\n",
    "    \"LazyBatchNorm1d\",\n",
    "    \"LazyBatchNorm2d\",\n",
    "    \"LazyBatchNorm3d\",\n",
    "]\n",
    "\n",
    "\"BatchNorm2d\" in batch_norm_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonoNet(nn.Module):\n",
    "    supported_models = [\"SN16\", \"SN32\", \"SN64\"]\n",
    "\n",
    "    feature_cfg_dict = {\n",
    "        \"SN16\": [16, 16, \"M\", 32, 32, \"M\", 64, 64, 64, \"M\", 128, 128, 128, \"M\", 128, 128, 128],\n",
    "        \"SN32\": [32, 32, \"M\", 64, 64, \"M\", 128, 128, 128, \"M\", 256, 256, 256, \"M\", 256, 256, 256],\n",
    "        \"SN64\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512],\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"SN64\",\n",
    "        output_size: int = 6,\n",
    "        pretrain: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert name in self.supported_models\n",
    "\n",
    "        feature_cfg = self.feature_cfg_dict[name]\n",
    "        self.features = self._make_feature_layers(feature_cfg, 1)\n",
    "\n",
    "        feature_channels = feature_cfg[-1]\n",
    "        adaption_channels = feature_channels // 2\n",
    "        self.adaption = self._make_adaption_layer(feature_channels, adaption_channels, 14)\n",
    "\n",
    "        if pretrain:\n",
    "            # weights_path = os.path.join(os.path.dirname(__file__), \"weights\", 'SonoNet{}.pth'.format(name[2:]))\n",
    "            weights_path = root / \"src\" / \"models\" / \"components\" / \"weights\" / f\"SonoNet{name[2:]}.pth\"\n",
    "            self.load_weights(weights_path)\n",
    "        else:\n",
    "            self.apply(self._initialize_weights)\n",
    "\n",
    "        self.adaption[3] = nn.Conv2d(adaption_channels, output_size, 1, bias=False)\n",
    "        self.adaption[4] = nn.BatchNorm2d(output_size)\n",
    "        self._initialize_weights(self.adaption[3])\n",
    "        self._initialize_weights(self.adaption[4])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = self.adaption(x)\n",
    "        y = F.avg_pool2d(x, x.size()[2:]).view(x.size(0), -1)\n",
    "        # y = F.softmax(y, dim=1)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    @classmethod\n",
    "    def _make_feature_layers(cls, feature_cfg, in_channels):\n",
    "        layers = []\n",
    "        conv_layers = []\n",
    "        for v in feature_cfg:\n",
    "            if v == \"M\":\n",
    "                conv_layers.append(nn.MaxPool2d(2))\n",
    "                layers.append(nn.Sequential(*conv_layers))\n",
    "                conv_layers = []\n",
    "            else:\n",
    "                conv_layers.append(cls._conv_layer(in_channels, v))\n",
    "                in_channels = v\n",
    "        layers.append(nn.Sequential(*conv_layers))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _conv_layer(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, eps=1e-4),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_adaption_layer(feature_channels, adaption_channels, num_labels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(feature_channels, adaption_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(adaption_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(adaption_channels, num_labels, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_labels),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _initialize_weights(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        state = torch.load(weights_path)\n",
    "        self.load_state_dict(state, strict=True)\n",
    "\n",
    "\n",
    "sononet = SonoNet(\n",
    "    name=\"SN64\",\n",
    "    output_size=6,\n",
    "    pretrain=True,\n",
    ")\n",
    "\n",
    "logits, y_hat = sononet(torch.rand(1, 1, 165, 240))\n",
    "print(logits.view(1, -1).shape)\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, y_hat = model(torch.rand(1, 1, 165, 240))\n",
    "print(logits.shape)\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(1, 1, 165, 240).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(0, 3, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(0, 3, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "i = torch.randint(0, 3, (1,))\n",
    "\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1], dtype=torch.float32)\n",
    "print(x)\n",
    "print(torch.mean(torch.cat([x])))\n",
    "print(torch.mean(torch.cat([x, x, x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(torch.mean(torch.cat([x]), dim=0))\n",
    "print(torch.mean(torch.cat([x, x, x]), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.tensor(float(\"-inf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.tensor([[0.0, 0.0, 0.0]])\n",
    "y = torch.tensor([1])\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.tensor([[float(\"-inf\"), float(\"-inf\"), 0.0, 0.0, 0.0]])\n",
    "y = torch.tensor([3])\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 0.0, 0.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[float(\"-inf\"), float(\"-inf\"), 0.0, 0.0, 0.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "mask = torch.tensor([1, 1, 0, 0, 0])\n",
    "torch.masked_fill(x, mask, value=float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = torch.nn.functional.one_hot(torch.arange(0, 3), num_classes=5)\n",
    "print(len(masks))\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "mask = torch.tensor([1, 1, 0, 0, 0], dtype=torch.bool)\n",
    "x.masked_fill(mask, value=float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(torch.tensor([1, 1, 0, 0, 0], dtype=torch.bool)):\n",
    "    if c:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "img = torch.zeros((2, 1, 8, 8))\n",
    "\n",
    "img.expand(-1, 3, -1, -1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
