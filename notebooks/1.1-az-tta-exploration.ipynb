{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchmetrics import (\n",
    "    Accuracy,\n",
    "    ConfusionMatrix,\n",
    "    F1Score,\n",
    "    MaxMetric,\n",
    "    MeanMetric,\n",
    "    Precision,\n",
    "    Recall,\n",
    ")\n",
    "from torchvision.io import read_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('png')\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import (\n",
    "    FetalBrainPlanesDataset,\n",
    "    USVideosDataset,\n",
    "    USVideosFrameDataset,\n",
    "    VideoQualityDataset,\n",
    ")\n",
    "from src.data.components.transforms import (\n",
    "    Affine,\n",
    "    HorizontalFlip,\n",
    "    LabelEncoder,\n",
    "    RandomPercentCrop,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "from src.models.quality_module import QualityLitModule\n",
    "\n",
    "data_dir = root / \"data\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-07_21-10-40\" / \"0\"  # frosty-forest-2691\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-26_07-45-41\"  # neat-aardvark-2941\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_03-38-18\"  # fine-lion-2828\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_13-37-18\"  # fresh-grass-2813\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-23_18-16-01\"  # prime-butterfly-2873\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-24_12-02-44\"  # lilac-frost-2893\n",
    "\n",
    "model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_21-48-38\"  # glowing-sea-2849\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_19-18-09\"  # swift-butterfly-2819\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-20_07-04-24\"  # sunny-flower-2780\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"\"  #\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Plot Videos Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_counts():\n",
    "    counts = {}\n",
    "    for min_probability in min_probabilities:\n",
    "        count = {}\n",
    "        for label in label_names:\n",
    "            count[label] = 0\n",
    "        counts[min_probability] = count\n",
    "    return counts\n",
    "\n",
    "\n",
    "def label_videos():\n",
    "    selected_path = video_dataset_dir / \"selected\"\n",
    "    videos = list(selected_path.iterdir())\n",
    "    for i, frames_path in enumerate(tqdm(videos, desc=\"Label videos\")):\n",
    "        label_video(frames_path)\n",
    "\n",
    "\n",
    "def label_video(frames_path: Path):\n",
    "    frames_paths = list(frames_path.iterdir())\n",
    "    epochs = ceil(len(frames_paths) / batch_size)\n",
    "    for i in range(epochs):\n",
    "        frames = frames_paths[(i * batch_size) : ((i + 1) * batch_size)]\n",
    "        label_frames(frames)\n",
    "\n",
    "\n",
    "def label_frames(frames):\n",
    "    with torch.no_grad():\n",
    "        frames = get_frames_tensor(frames)\n",
    "        frames = frames.to(model.device)\n",
    "\n",
    "        results = [model(t(frames))[1] for t in transforms]\n",
    "        logits = torch.mean(torch.stack(results, dim=1), dim=1)\n",
    "\n",
    "        y_hats = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        count_labels(y_hats, preds)\n",
    "\n",
    "\n",
    "def get_frames_tensor(frame_paths):\n",
    "    frames = []\n",
    "    for frame_path in frame_paths:\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frames.append(frame)\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "\n",
    "def count_labels(y_hats, preds):\n",
    "    for y_hat, pred in zip(y_hats, preds):\n",
    "        for min_probability in min_probabilities:\n",
    "            if y_hat[pred] > min_probability:\n",
    "                counts[min_probability][label_names[pred]] += 1\n",
    "\n",
    "\n",
    "video_dataset_dir = data_dir / \"US_VIDEOS_0.3\"\n",
    "label_names = FetalBrainPlanesDataset.labels\n",
    "min_probabilities = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995]\n",
    "counts = init_counts()\n",
    "\n",
    "horizontal_flips = [False]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        HorizontalFlip(flip=horizontal_flip),\n",
    "        VerticalFlip(flip=vertical_flip),\n",
    "        Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for horizontal_flip, vertical_flip, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "batch_size = 32\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "label_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_videos_probabilities(counts):\n",
    "    with plt.style.context(\"seaborn-v0_8-muted\"):\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    for i, (min_prob, count) in enumerate(counts.items()):\n",
    "        labels = list(count.keys())\n",
    "        values = list(count.values())\n",
    "        ax.bar(labels, values, label=str(min_prob))\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Probabilities on video dataset\")\n",
    "\n",
    "\n",
    "plot_videos_probabilities(counts)\n",
    "plt.show()\n",
    "plt.savefig(str(model_log_dir / \"plot_videos_probabilities.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Test-Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = FetalBrainPlanesDataset.labels\n",
    "\n",
    "test = FetalBrainPlanesDataset(\n",
    "    data_dir=data_dir,\n",
    "    train=False,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(labels=label_names),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    epochs = ceil(len(test) / batch_size)\n",
    "\n",
    "    logits_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    for epoch_idx in tqdm(range(epochs), desc=\"Evaluate\"):\n",
    "        batch = [test[i] for i in range(epoch_idx * batch_size, (epoch_idx + 1) * batch_size) if i < len(test)]\n",
    "        x = torch.stack([x for x, _ in batch])\n",
    "        y = torch.stack([y for _, y in batch])\n",
    "\n",
    "        x = x.to(model.device)\n",
    "        logits_batch = [evaluate_x(x, tran) for tran in tqdm(transforms, desc=\"Transforms\", leave=False)]\n",
    "        logits_batch = torch.stack(logits_batch, dim=1)\n",
    "\n",
    "        logits_batches.append(logits_batch)\n",
    "        y_batches.append(y)\n",
    "\n",
    "    return torch.cat(logits_batches, dim=0), torch.cat(y_batches, dim=0)\n",
    "\n",
    "\n",
    "def evaluate_x(x, transform):\n",
    "    with torch.no_grad():\n",
    "        x = transform(x)\n",
    "        _, logits = model(x)\n",
    "        return logits.cpu()\n",
    "\n",
    "\n",
    "# horizontal_flips=[False]\n",
    "horizontal_flips = [False, True]\n",
    "\n",
    "vertical_flips = [False, True]\n",
    "\n",
    "# rotate_degrees=[0]\n",
    "# rotate_degrees=[0, -5, 5]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "# rotate_degrees = [0, -5, -10, -15, 5, 10, 15]\n",
    "\n",
    "# translates=[(0.0, 0.0)]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "# translates = list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1]))\n",
    "\n",
    "# scales=[1.0]\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        \"horizontal_flip\": horizontal_flip,\n",
    "        \"vertical_flips\": vertical_flips,\n",
    "        \"rotate_degree\": rotate_degree,\n",
    "        \"translate\": translate,\n",
    "        \"scale\": scale,\n",
    "    }\n",
    "    for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        HorizontalFlip(flip=param[\"horizontal_flip\"]),\n",
    "        VerticalFlip(flip=param[\"vertical_flips\"]),\n",
    "        Affine(degrees=param[\"rotate_degree\"], translate=param[\"translate\"], scale=param[\"scale\"]),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for param in params\n",
    "]\n",
    "\n",
    "batch_size = 32 * 6\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(y_hats.shape)\n",
    "print(target.shape)\n",
    "# ~20:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return acc(pred, target).item()\n",
    "\n",
    "\n",
    "print(accuracy(y_hats, target))\n",
    "print(accuracy(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    prec = Precision(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return prec(pred, target).item()\n",
    "\n",
    "\n",
    "print(precision(y_hats, target))\n",
    "print(precision(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    rec = Recall(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return rec(pred, target).item()\n",
    "\n",
    "\n",
    "print(recall(y_hats, target))\n",
    "print(recall(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1Score(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return f1(pred, target).item()\n",
    "\n",
    "\n",
    "print(f1Score(y_hats, target))\n",
    "print(f1Score(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_stats(y_hats, target):\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    prec = Precision(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    rec = Recall(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc(pred, target).cpu().numpy(),\n",
    "        \"Precision\": prec(pred, target).cpu().numpy(),\n",
    "        \"Recall\": rec(pred, target).cpu().numpy(),\n",
    "        \"F1-score\": f1(pred, target).cpu().numpy(),\n",
    "    }\n",
    "\n",
    "\n",
    "with pd.option_context(\"display.float_format\", \"{:0.3f}\".format):\n",
    "    print(pd.DataFrame(all_stats(y_hats, target), index=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def confusion_matrix(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(label_names))\n",
    "    cm_norm = ConfusionMatrix(task=\"multiclass\", num_classes=len(label_names), normalize=\"true\")\n",
    "\n",
    "    return cm(pred, target).cpu().numpy(), cm_norm(pred, target).cpu().numpy()\n",
    "\n",
    "\n",
    "cm, cm_norm = confusion_matrix(y_hats, target)\n",
    "\n",
    "cm_txt = []\n",
    "for row, row_norm in zip(cm, cm_norm):\n",
    "    row_txt = []\n",
    "    for cell, cell_norm in zip(row, row_norm):\n",
    "        txt = \"{quantity}\\n{perc:.2f}%\".format(quantity=cell, perc=cell_norm * 100)\n",
    "        row_txt.append(txt)\n",
    "    cm_txt.append(row_txt)\n",
    "cm_txt = np.array(cm_txt)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "fx = sns.heatmap(\n",
    "    cm_norm,\n",
    "    # annot=True,\n",
    "    # fmt=\".3f\",\n",
    "    annot=cm,\n",
    "    fmt=\".0f\",\n",
    "    # annot=cm_txt,\n",
    "    # fmt=\"\",\n",
    "    square=True,\n",
    "    cmap=sns.dark_palette(\"#69d\", as_cmap=True),\n",
    "    cbar=False,\n",
    "    xticklabels=label_names,\n",
    "    # yticklabels=label_names,\n",
    "    yticklabels=[\"Trans\\nventricular\", \"Trans\\nthalamic\", \"Trans\\ncerebellum\", \"Other\", \"Not A Brain\"],\n",
    "    annot_kws={\"size\": 12},\n",
    ")\n",
    "\n",
    "# labels the title and x, y axis of plot\n",
    "# fx.set_title(\"Plotting Confusion Matrix using Seaborn\\n\\n\")\n",
    "fx.set_xlabel(\"Predicted Labels\", size=16)\n",
    "fx.set_ylabel(\"True Labels\", size=16)\n",
    "\n",
    "fx.set_xticklabels(fx.get_xticklabels(), rotation=30, fontsize=12)\n",
    "fx.set_yticklabels(fx.get_yticklabels(), rotation=0, fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/confusion_matrix.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-10_08-36-16\" / \"0\"  # graceful-plasma-2705\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(accuracy(y_hats, target))\n",
    "print(accuracy(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_score = pd.DataFrame(params)\n",
    "individual_score[\"accuracy\"] = [accuracy(y_hats[:, [i]], target) for i in range(y_hats.size(1))]\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):  # more options can be specified also\n",
    "    print(individual_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(left, n):\n",
    "    if n == 1:\n",
    "        return [[v] for v in left]\n",
    "\n",
    "    rs = gen(left, n - 1)\n",
    "\n",
    "    rrs = []\n",
    "    for v in left:\n",
    "        for r in rs:\n",
    "            rrs.append(r + [v])\n",
    "    return rrs\n",
    "\n",
    "\n",
    "def cumulative_accuracy(row):\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        add = True\n",
    "        for key, value in params[0].items():\n",
    "            if row[key] == \"-\" and param[key] != value:\n",
    "                add = False\n",
    "\n",
    "        if add:\n",
    "            idxs.append(i)\n",
    "\n",
    "    return accuracy(y_hats[:, idxs], target)\n",
    "\n",
    "\n",
    "cumulative_score = pd.DataFrame(gen([\"-\", \"+\"], 5), columns=params[0].keys())\n",
    "cumulative_score[\"accuracy\"] = [cumulative_accuracy(cumulative_score.loc[i]) for i in range(len(cumulative_score))]\n",
    "cumulative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        for agr_param in aggregate_params:\n",
    "            if param == agr_param:\n",
    "                idxs.append(i)\n",
    "\n",
    "    return (\n",
    "        accuracy(y_hats[:, idxs], target),\n",
    "        precision(y_hats[:, idxs], target),\n",
    "        recall(y_hats[:, idxs], target),\n",
    "        f1Score(y_hats[:, idxs], target),\n",
    "    )\n",
    "\n",
    "\n",
    "aggregate_score(\n",
    "    # horizontal_flips=[False],\n",
    "    horizontal_flips=[False, True],\n",
    "    # vertical_flips=[False],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0],\n",
    "    # rotate_degrees=[0, -5, 5],\n",
    "    # rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    # rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    # translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    # translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    scales=[1.0],\n",
    "    # scales=[1.0, 1.05],\n",
    "    # scales=[1.0, 1.05, 1.10],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    return [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "scores = search_aggregate_score(\n",
    "    horizontal_flips=[[False], [False, True]],\n",
    "    vertical_flips=[[False], [False, True]],\n",
    "    rotate_degrees=[[0], [0, -5, 5], [0, -5, -10, 5, 10]],  # [0, -5, -10, -15, 5, 10, 15]\n",
    "    translates=[[(0.0, 0.0)], [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]],\n",
    "    scales=[[1.0], [1.0, 1.05, 1.10], [1.0, 1.05, 1.10, 1.15, 1.20]],\n",
    ")\n",
    "\n",
    "print(\"Best score\")\n",
    "pprint(max(scores, key=lambda x: x[\"score\"][3]))\n",
    "print(\"\")\n",
    "# sorted(scores, key=lambda x: x[\"score\"][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    horizontal_flips = perm(horizontal_flips)\n",
    "    vertical_flips = perm(vertical_flips)\n",
    "    rotate_degrees = perm(rotate_degrees)\n",
    "    translates = perm(translates)\n",
    "    scales = perm(scales)\n",
    "\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return max(aggregate_params, key=lambda x: x[\"score\"][0])\n",
    "\n",
    "\n",
    "def perm(values):\n",
    "    list_of_lists = [list(itertools.combinations(values, i + 1)) for i in range(len(values))]\n",
    "    return list(itertools.chain(*list_of_lists))\n",
    "\n",
    "\n",
    "greed_search_aggregate_score(\n",
    "    # horizontal_flips=[False],\n",
    "    horizontal_flips=[False, True],\n",
    "    # vertical_flips=[False],\n",
    "    vertical_flips=[False, True],\n",
    "    # rotate_degrees=[0],\n",
    "    # rotate_degrees=[0, -5, 5],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    # rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    # translates=[(0.0, 0.0)],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    # translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    # scales=[1.0],\n",
    "    # scales=[1.0, 1.05],\n",
    "    # scales=[1.0, 1.05, 1.10],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neat-aardvark-2941\n",
    "# fine-lion-2828\n",
    "# fresh-grass-2813\n",
    "# prime-butterfly-2873\n",
    "# lilac-frost-2893\n",
    "\n",
    "horizontal_flips = [False]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "# 0.7860984802246094 0.7706203460693359\n",
    "# 0.7940822243690491 0.7465180754661560\n",
    "# 0.7963624000549316 0.7576579451560974\n",
    "# 0.8050662279129028 0.7383250594139099\n",
    "# 0.7890244722366333 0.7428253293037415\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, 5]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10]\n",
    "# 0.7951812148094177 0.7918230891227720\n",
    "# 0.8120790719985962 0.7782592773437500\n",
    "# 0.7909176945686340 0.7713555693626404\n",
    "# 0.7989473342895508 0.7635297179222107\n",
    "# 0.7967666387557983 0.7601540088653564\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, 5]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7991837859153748 0.7918857336044310\n",
    "# 0.8086183667182922 0.7752655148506165\n",
    "# 0.7911577224731445 0.7767201662063599\n",
    "# 0.8024842739105225 0.7718890905380249\n",
    "# 0.8025256395339966 0.7683259844779968\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10]\n",
    "# 0.7910797595977783 0.7876892685890198\n",
    "# 0.8088076710700989 0.7740747332572937\n",
    "# 0.7852406501770020 0.7671951055526733\n",
    "# 0.8035995960235596 0.7657317519187927\n",
    "# 0.7966942787170410 0.7604588270187378\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7969303131103516 0.7968350648880005\n",
    "# 0.8065788745880127 0.7735700011253350\n",
    "# 0.7919420599937439 0.7783745527267456\n",
    "# 0.8007959127426147 0.7693001031875610\n",
    "# 0.8012878894805908 0.7667553424835205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playful-haze-2111\n",
    "# mix_ra\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_14-32-35\" / \"4\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "\n",
    "# 0.7875436544418335\n",
    "# 0.8037662506103516\n",
    "# 0.821164608001709\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.8078333735466003\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.8159346580505371\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.821164608001709\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "#\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.8252905011177063"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
