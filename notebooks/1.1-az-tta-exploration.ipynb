{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchvision.io import read_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('png')\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import (\n",
    "    FetalBrainPlanesDataset,\n",
    "    USVideosDataset,\n",
    "    USVideosFrameDataset,\n",
    "    VideoQualityDataset,\n",
    ")\n",
    "from src.data.components.transforms import (\n",
    "    Affine,\n",
    "    HorizontalFlip,\n",
    "    LabelEncoder,\n",
    "    RandomPercentCrop,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "from src.models.quality_module import QualityLitModule\n",
    "\n",
    "data_dir = root / \"data\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-07_21-10-40\" / \"0\"  # frosty-forest-2691\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Plot Videos Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_counts():\n",
    "    counts = {}\n",
    "    for min_probability in min_probabilities:\n",
    "        count = {}\n",
    "        for label in label_names:\n",
    "            count[label] = 0\n",
    "        counts[min_probability] = count\n",
    "    return counts\n",
    "\n",
    "\n",
    "def label_videos():\n",
    "    selected_path = video_dataset_dir / \"selected\"\n",
    "    videos = list(selected_path.iterdir())\n",
    "    for i, frames_path in enumerate(tqdm(videos, desc=\"Label videos\")):\n",
    "        label_video(frames_path)\n",
    "\n",
    "\n",
    "def label_video(frames_path: Path):\n",
    "    frames_paths = list(frames_path.iterdir())\n",
    "    epochs = ceil(len(frames_paths) / batch_size)\n",
    "    for i in range(epochs):\n",
    "        frames = frames_paths[(i * batch_size) : ((i + 1) * batch_size)]\n",
    "        label_frames(frames)\n",
    "\n",
    "\n",
    "def label_frames(frames):\n",
    "    with torch.no_grad():\n",
    "        frames = get_frames_tensor(frames)\n",
    "        frames = frames.to(model.device)\n",
    "\n",
    "        results = [model(t(frames))[1] for t in transforms]\n",
    "        logits = torch.mean(torch.stack(results, dim=1), dim=1)\n",
    "\n",
    "        y_hats = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        count_labels(y_hats, preds)\n",
    "\n",
    "\n",
    "def get_frames_tensor(frame_paths):\n",
    "    frames = []\n",
    "    for frame_path in frame_paths:\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frames.append(frame)\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "\n",
    "def count_labels(y_hats, preds):\n",
    "    for y_hat, pred in zip(y_hats, preds):\n",
    "        for min_probability in min_probabilities:\n",
    "            if y_hat[pred] > min_probability:\n",
    "                counts[min_probability][label_names[pred]] += 1\n",
    "\n",
    "\n",
    "video_dataset_dir = data_dir / \"US_VIDEOS_0.3\"\n",
    "label_names = FetalBrainPlanesDataset.labels\n",
    "min_probabilities = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995]\n",
    "counts = init_counts()\n",
    "\n",
    "horizontal_flips = [False]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        HorizontalFlip(flip=horizontal_flip),\n",
    "        VerticalFlip(flip=vertical_flip),\n",
    "        Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for horizontal_flip, vertical_flip, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "batch_size = 32\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "label_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_videos_probabilities(counts):\n",
    "    with plt.style.context(\"seaborn-v0_8-muted\"):\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    for i, (min_prob, count) in enumerate(counts.items()):\n",
    "        labels = list(count.keys())\n",
    "        values = list(count.values())\n",
    "        ax.bar(labels, values, label=str(min_prob))\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Probabilities on video dataset\")\n",
    "\n",
    "\n",
    "plot_videos_probabilities(counts)\n",
    "plt.show()\n",
    "plt.savefig(str(model_log_dir / \"plot_videos_probabilities.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Test-Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = FetalBrainPlanesDataset.labels\n",
    "\n",
    "test = FetalBrainPlanesDataset(\n",
    "    data_dir=data_dir,\n",
    "    train=False,\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(labels=label_names),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    epochs = ceil(len(test) / batch_size)\n",
    "\n",
    "    logits_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    for epoch_idx in tqdm(range(epochs), desc=\"Evaluate\"):\n",
    "        batch = [test[i] for i in range(epoch_idx * batch_size, (epoch_idx + 1) * batch_size) if i < len(test)]\n",
    "        x = torch.stack([x for x, _ in batch])\n",
    "        y = torch.stack([y for _, y in batch])\n",
    "\n",
    "        x = x.to(model.device)\n",
    "        logits_batch = [evaluate_x(x, tran) for tran in tqdm(transforms, desc=\"Transforms\", leave=False)]\n",
    "        logits_batch = torch.stack(logits_batch, dim=1)\n",
    "\n",
    "        logits_batches.append(logits_batch)\n",
    "        y_batches.append(y)\n",
    "\n",
    "    return torch.cat(logits_batches, dim=0), torch.cat(y_batches, dim=0)\n",
    "\n",
    "\n",
    "def evaluate_x(x, transform):\n",
    "    with torch.no_grad():\n",
    "        x = transform(x)\n",
    "        _, logits = model(x)\n",
    "        return logits.cpu()\n",
    "\n",
    "\n",
    "# horizontal_flips=[False]\n",
    "horizontal_flips = [False, True]\n",
    "\n",
    "vertical_flips = [False, True]\n",
    "\n",
    "# rotate_degrees=[0]\n",
    "# rotate_degrees=[0, -5, 5]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "# rotate_degrees = [0, -5, -10, -15, 5, 10, 15]\n",
    "\n",
    "# translates=[(0.0, 0.0)]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "# translates = list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1]))\n",
    "\n",
    "# scales=[1.0]\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        \"horizontal_flip\": horizontal_flip,\n",
    "        \"vertical_flips\": vertical_flips,\n",
    "        \"rotate_degree\": rotate_degree,\n",
    "        \"translate\": translate,\n",
    "        \"scale\": scale,\n",
    "    }\n",
    "    for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        HorizontalFlip(flip=param[\"horizontal_flip\"]),\n",
    "        VerticalFlip(flip=param[\"vertical_flips\"]),\n",
    "        Affine(degrees=param[\"rotate_degree\"], translate=param[\"translate\"], scale=param[\"scale\"]),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for param in params\n",
    "]\n",
    "\n",
    "batch_size = 32 * 6\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(y_hats.shape)\n",
    "print(target.shape)\n",
    "# ~20:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return acc(pred, target).item()\n",
    "\n",
    "\n",
    "print(accuracy(y_hats, target))  # acc_tta 0.8037662506103516 0.821164608001709\n",
    "print(accuracy(y_hats[:, [0]], target))  # acc 0.7875436544418335"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-10_08-36-16\" / \"0\"  # graceful-plasma-2705\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(accuracy(y_hats, target))  # acc_tta 0.8037662506103516 0.821164608001709\n",
    "print(accuracy(y_hats[:, [0]], target))  # acc 0.7875436544418335"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_score = pd.DataFrame(params)\n",
    "individual_score[\"accuracy\"] = [accuracy(y_hats[:, [i]], target) for i in range(y_hats.size(1))]\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):  # more options can be specified also\n",
    "    print(individual_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(left, n):\n",
    "    if n == 1:\n",
    "        return [[v] for v in left]\n",
    "\n",
    "    rs = gen(left, n - 1)\n",
    "\n",
    "    rrs = []\n",
    "    for v in left:\n",
    "        for r in rs:\n",
    "            rrs.append(r + [v])\n",
    "    return rrs\n",
    "\n",
    "\n",
    "def cumulative_accuracy(row):\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        add = True\n",
    "        for key, value in params[0].items():\n",
    "            if row[key] == \"-\" and param[key] != value:\n",
    "                add = False\n",
    "\n",
    "        if add:\n",
    "            idxs.append(i)\n",
    "\n",
    "    return accuracy(y_hats[:, idxs], target)\n",
    "\n",
    "\n",
    "cumulative_score = pd.DataFrame(gen([\"-\", \"+\"], 5), columns=params[0].keys())\n",
    "cumulative_score[\"accuracy\"] = [cumulative_accuracy(cumulative_score.loc[i]) for i in range(len(cumulative_score))]\n",
    "cumulative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        for agr_param in aggregate_params:\n",
    "            if param == agr_param:\n",
    "                idxs.append(i)\n",
    "\n",
    "    return accuracy(y_hats[:, idxs], target)\n",
    "\n",
    "\n",
    "aggregate_score(\n",
    "    horizontal_flips=[False],\n",
    "    # horizontal_flips=[False, True],\n",
    "    vertical_flips=[False],\n",
    "    # vertical_flips=[False, True],\n",
    "    rotate_degrees=[0],\n",
    "    # rotate_degrees=[0, -5, 5],\n",
    "    # rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    # rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    # translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    # translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    scales=[1.0],\n",
    "    # scales=[1.0, 1.05],\n",
    "    # scales=[1.0, 1.05, 1.10],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    return [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "scores = search_aggregate_score(\n",
    "    horizontal_flips=[[False], [False, True]],\n",
    "    vertical_flips=[[False], [False, True]],\n",
    "    rotate_degrees=[[0], [0, -5, 5], [0, -5, -10, 5, 10]],\n",
    "    translates=[[(0.0, 0.0)], [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]],\n",
    "    scales=[[1.0], [1.0, 1.05, 1.10], [1.0, 1.05, 1.10, 1.15, 1.20]],\n",
    ")\n",
    "\n",
    "print(\"Best score\")\n",
    "pprint(max(scores, key=lambda x: x[\"score\"]))\n",
    "print(\"\")\n",
    "sorted(scores, key=lambda x: x[\"score\"], reverse=True)  # 0.8133314251899719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    horizontal_flips = perm(horizontal_flips)\n",
    "    vertical_flips = perm(vertical_flips)\n",
    "    rotate_degrees = perm(rotate_degrees)\n",
    "    translates = perm(translates)\n",
    "    scales = perm(scales)\n",
    "\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return max(aggregate_params, key=lambda x: x[\"score\"])\n",
    "\n",
    "\n",
    "def perm(values):\n",
    "    list_of_lists = [list(itertools.combinations(values, i + 1)) for i in range(len(values))]\n",
    "    return list(itertools.chain(*list_of_lists))\n",
    "\n",
    "\n",
    "greed_search_aggregate_score(\n",
    "    #     horizontal_flips=[False],\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False],\n",
    "    #     rotate_degrees=[0],\n",
    "    #     rotate_degrees=[0, -5, 5],\n",
    "    #     rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    #     translates=[(0.0, 0.0)],\n",
    "    #     translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    #     scales=[1.0],\n",
    "    #     scales=[1.0, 1.05],\n",
    "    #     scales=[1.0, 1.05, 1.10],\n",
    "    #     scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    #     scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    #     scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VTA?\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "# 0.8037662506103516\n",
    "# 0.7986749410629272\n",
    "# 0.7922136783599854\n",
    "# 0.7947545051574707\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "# 0.8122719526290894\n",
    "# 0.8002059459686279\n",
    "# 0.7947515249252319\n",
    "# 0.7977738380432129\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15]\n",
    "# 0.8118382096290588\n",
    "# 0.7972695827484131\n",
    "# 0.789408266544342\n",
    "# 0.7966556549072266\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.814094603061676\n",
    "# 0.8002622723579407\n",
    "# 0.7918455600738525\n",
    "# 0.7956793308258057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playful-haze-2111\n",
    "# mix_ra\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_14-32-35\" / \"4\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "\n",
    "# 0.7875436544418335\n",
    "# 0.8037662506103516\n",
    "# 0.821164608001709\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.8078333735466003\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.8159346580505371\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.821164608001709\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "#\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.8252905011177063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lunar-terrain-2133\n",
    "# rac\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-23_12-16-05\" / \"0\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15]\n",
    "\n",
    "# 0.7939079403877258\n",
    "# 0.7986749410629272\n",
    "# 0.8068532943725586\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.8031753301620483\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.8068532943725586\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.8048830628395081\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# 0.7977616190910339\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.7976198792457581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry-resonance-2119\n",
    "# mix_rac_ra\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_18-04-17\" / \"5\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "\n",
    "# 0.7930771708488464\n",
    "# 0.7922136783599854\n",
    "# 0.7974439263343811\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.7962639927864075\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.7965254187583923\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7974439263343811\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# 0.7974885106086731\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.7954345941543579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast-shadow-2103\n",
    "# mix_rac\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_11-42-40\" / \"3\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, -15, 5, 10, 15]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0]\n",
    "\n",
    "# 0.782551646232605\n",
    "# 0.7947545051574707\n",
    "# 0.8007570505142212\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.7916216850280762\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.7899205684661865\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7916465997695923\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# 0.7920457124710083\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.7914426326751709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faithful-jazz-2130\n",
    "# mix_ra\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-23_01-59-06\" / \"4\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0)]\n",
    "# translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "\n",
    "# 0.7793711423873901\n",
    "# 0.792731761932373\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
