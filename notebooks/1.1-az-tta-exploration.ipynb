{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pathlib\n",
    "import shutil\n",
    "from math import ceil, sqrt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch import Tensor\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from torchmetrics import (\n",
    "    Accuracy,\n",
    "    ConfusionMatrix,\n",
    "    F1Score,\n",
    "    MaxMetric,\n",
    "    MeanMetric,\n",
    "    Precision,\n",
    "    Recall,\n",
    ")\n",
    "from torchvision.io import read_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('png')\n",
    "\n",
    "root = rootutils.setup_root(search_from=\".\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.data.components.dataset import (\n",
    "    FetalBrainPlanesDataset,\n",
    "    USVideosDataset,\n",
    "    USVideosFrameDataset,\n",
    "    VideoQualityDataset,\n",
    ")\n",
    "from src.data.components.transforms import (\n",
    "    Affine,\n",
    "    HorizontalFlip,\n",
    "    LabelEncoder,\n",
    "    RandomPercentCrop,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from src.data.utils.utils import show_numpy_images, show_pytorch_images\n",
    "from src.models.fetal_module import FetalLitModule\n",
    "from src.models.quality_module import QualityLitModule\n",
    "\n",
    "data_dir = root / \"data\"\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-07_21-10-40\" / \"0\"  # frosty-forest-2691\n",
    "\n",
    "\n",
    "model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_22-41-24\"  # civilized-droid-3054\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-05_09-31-12\"  # carbonite-ewok-3069\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_14-12-45\"  # tusken-transport-3040\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2025-05-05_02-41-36\"  # tusken-ewok-3060 best test/acc\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-26_07-45-41\"  # neat-aardvark-2941\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_03-38-18\"  # fine-lion-2828\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_13-37-18\"  # fresh-grass-2813\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-23_18-16-01\"  # prime-butterfly-2873\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-24_12-02-44\"  # lilac-frost-2893\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-22_21-48-38\"  # glowing-sea-2849\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-21_19-18-09\"  # swift-butterfly-2819\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"2024-06-20_07-04-24\"  # sunny-flower-2780\n",
    "\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"runs\" / \"\"  #\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.hparams.net_spec.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Plot Videos Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_counts():\n",
    "    counts = {}\n",
    "    for min_probability in min_probabilities:\n",
    "        count = {}\n",
    "        for label in label_names:\n",
    "            count[label] = 0\n",
    "        counts[min_probability] = count\n",
    "    return counts\n",
    "\n",
    "\n",
    "def label_videos():\n",
    "    selected_path = video_dataset_dir / \"images\"\n",
    "    videos = list(selected_path.iterdir())\n",
    "    for i, frames_path in enumerate(tqdm(videos, desc=\"Label videos\")):\n",
    "        label_video(frames_path)\n",
    "        # break\n",
    "\n",
    "\n",
    "def label_video(frames_path: Path):\n",
    "    frames_paths = list(frames_path.iterdir())\n",
    "    epochs = ceil(len(frames_paths) / batch_size)\n",
    "    for i in range(epochs):\n",
    "        frames = frames_paths[(i * batch_size) : ((i + 1) * batch_size)]\n",
    "        label_frames(frames)\n",
    "        # break\n",
    "\n",
    "\n",
    "# def label_frames(frames):\n",
    "#     with torch.no_grad():\n",
    "#         frames = get_frames_tensor(frames)\n",
    "#         frames = frames.to(model.device)\n",
    "\n",
    "#         results = [model(t(frames))[1] for t in transforms]\n",
    "#         logits = torch.mean(torch.stack(results, dim=1), dim=1)\n",
    "\n",
    "#         y_hats = F.softmax(logits, dim=1)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         count_labels(y_hats, preds)\n",
    "#         sample_classes(frames, y_hats, preds)\n",
    "\n",
    "\n",
    "def label_frames(frames):\n",
    "    with torch.no_grad():\n",
    "        frames = get_frames_tensor(frames)\n",
    "        frames = frames.to(model.device)\n",
    "\n",
    "        results = [F.softmax(model(t(frames))[1], dim=1) for t in transforms]\n",
    "        y_hats = torch.mean(torch.stack(results, dim=1), dim=1)\n",
    "\n",
    "        preds = torch.argmax(y_hats, dim=1)\n",
    "        count_labels(y_hats, preds)\n",
    "        sample_classes(frames, y_hats, preds)\n",
    "\n",
    "\n",
    "# def label_frames(frames):\n",
    "#     with torch.no_grad():\n",
    "#         frames = get_frames_tensor(frames)\n",
    "\n",
    "#         y_hats_models = []\n",
    "#         for model in models:\n",
    "#             frames = frames.to(model.device)\n",
    "#             results = [model(t(frames))[1] for t in transforms]\n",
    "#             logits = torch.mean(torch.stack(results, dim=1), dim=1)\n",
    "\n",
    "#             y_hats = F.softmax(logits, dim=1)\n",
    "#             y_hats_models.append(y_hats)\n",
    "\n",
    "#         y_hats = torch.mean(torch.stack(y_hats_models, dim=1), dim=1)\n",
    "#         preds = torch.argmax(y_hats, dim=1)\n",
    "#         count_labels(y_hats, preds)\n",
    "#         sample_classes(frames, y_hats, preds)\n",
    "\n",
    "\n",
    "def get_frames_tensor(frame_paths):\n",
    "    frames = []\n",
    "    for frame_path in frame_paths:\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        frame = PIL.Image.fromarray(frame)\n",
    "        frame = TF.to_tensor(frame)\n",
    "        frames.append(frame)\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "\n",
    "def count_labels(y_hats, preds):\n",
    "    for y_hat, pred in zip(y_hats, preds):\n",
    "        for min_probability in min_probabilities:\n",
    "            if y_hat[pred] > min_probability:\n",
    "                counts[min_probability][label_names[pred]] += 1\n",
    "\n",
    "\n",
    "def init_samples():\n",
    "    counts = {}\n",
    "    for label in label_names:\n",
    "        count = {}\n",
    "        for min_probability in min_probabilities:\n",
    "            count[min_probability] = []\n",
    "        counts[label] = count\n",
    "    return counts\n",
    "\n",
    "\n",
    "def sample_classes(frames, y_hats, preds):\n",
    "    for frame, y_hat, pred in zip(frames, y_hats, preds):\n",
    "        for min_probability, max_probability in zip(min_probabilities, min_probabilities[1:] + [1.0]):\n",
    "            if y_hat[pred] > min_probability and y_hat[pred] <= max_probability:\n",
    "                samples[label_names[pred]][min_probability].append(frame.to(\"cpu\"))\n",
    "\n",
    "\n",
    "video_dataset_dir = data_dir / \"US_VIDEOS_ssim_0.7\"\n",
    "label_names = FetalBrainPlanesDataset.labels\n",
    "min_probabilities = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995]\n",
    "counts = init_counts()\n",
    "samples = init_samples()\n",
    "\n",
    "horizontal_flips = [False]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        HorizontalFlip(flip=horizontal_flip),\n",
    "        VerticalFlip(flip=vertical_flip),\n",
    "        Affine(degrees=rotate_degree, translate=translate, scale=scale),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for horizontal_flip, vertical_flip, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "batch_size = 32\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "# model.to(\"cuda\")\n",
    "\n",
    "label_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_videos_probabilities(counts):\n",
    "    with plt.style.context(\"seaborn-v0_8-muted\"):\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    for i, (min_prob, count) in enumerate(counts.items()):\n",
    "        labels = list(count.keys())\n",
    "        values = list(count.values())\n",
    "        ax.bar(labels, values, label=str(min_prob))\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Probabilities on video dataset\")\n",
    "\n",
    "\n",
    "plot_videos_probabilities(counts)\n",
    "plt.show()\n",
    "plt.savefig(str(model_log_dir / \"plot_videos_probabilities.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(label, probability, images):\n",
    "    sample_images = samples[label][probability]\n",
    "    idxs = torch.randint(0, len(sample_images), (images,))\n",
    "    sample_images = [sample_images[idx] for idx in idxs]\n",
    "\n",
    "    n = ceil(sqrt(len(sample_images)))\n",
    "    figsize = 16\n",
    "    scale = 165 / 230\n",
    "    fig, axes = plt.subplots(ncols=n, nrows=n, squeeze=False, figsize=(figsize, figsize * scale))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i * n + j >= len(sample_images):\n",
    "                continue\n",
    "\n",
    "            img = sample_images[i * n + j]\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = img.detach()\n",
    "            img = TF.to_pil_image(img)\n",
    "            img = TF.to_grayscale(img)\n",
    "            axes[i, j].imshow(np.asarray(img), cmap=\"gray\")\n",
    "\n",
    "    title = f\"Probability {probability}\"\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            axes[i, j].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    fig.tight_layout(h_pad=0.1, w_pad=0.1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# min_probabilities = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995]\n",
    "show_samples(\"Other\", 0.5, 9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Test-Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = FetalBrainPlanesDataset.labels\n",
    "\n",
    "test = FetalBrainPlanesDataset(\n",
    "    data_dir=data_dir,\n",
    "    subset=\"test\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(labels=label_names),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    epochs = ceil(len(test) / batch_size)\n",
    "\n",
    "    logits_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    for epoch_idx in tqdm(range(epochs), desc=\"Evaluate\"):\n",
    "        batch = [test[i] for i in range(epoch_idx * batch_size, (epoch_idx + 1) * batch_size) if i < len(test)]\n",
    "        x = torch.stack([x for x, _ in batch])\n",
    "        y = torch.stack([y for _, y in batch])\n",
    "\n",
    "        x = x.to(model.device)\n",
    "        logits_batch = [evaluate_x(x, tran) for tran in tqdm(transforms, desc=\"Transforms\", leave=False)]\n",
    "        logits_batch = torch.stack(logits_batch, dim=1)\n",
    "\n",
    "        logits_batches.append(logits_batch)\n",
    "        y_batches.append(y)\n",
    "\n",
    "    return torch.cat(logits_batches, dim=0), torch.cat(y_batches, dim=0)\n",
    "\n",
    "\n",
    "def evaluate_x(x, transform):\n",
    "    with torch.no_grad():\n",
    "        x = transform(x)\n",
    "        _, logits = model(x)\n",
    "        return logits.cpu()\n",
    "\n",
    "\n",
    "# horizontal_flips = [False]\n",
    "horizontal_flips = [False, True]\n",
    "\n",
    "# vertical_flips = [False]\n",
    "vertical_flips = [False, True]\n",
    "\n",
    "# rotate_degrees = [0]\n",
    "rotate_degrees = [0, -5, 5]\n",
    "# rotate_degrees = [0, -5, -10, 5, 10]\n",
    "# rotate_degrees = [0, -5, -10, -15, 5, 10, 15]\n",
    "\n",
    "translates = [(0.0, 0.0)]\n",
    "# translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "# translates = list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1]))\n",
    "\n",
    "# scales = [1.0]\n",
    "scales = [1.0, 1.10]\n",
    "# scales = [1.0, 1.05, 1.10]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "# scales = [1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        \"horizontal_flip\": horizontal_flip,\n",
    "        \"vertical_flips\": vertical_flips,\n",
    "        \"rotate_degree\": rotate_degree,\n",
    "        \"translate\": translate,\n",
    "        \"scale\": scale,\n",
    "    }\n",
    "    for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "        horizontal_flips,\n",
    "        vertical_flips,\n",
    "        rotate_degrees,\n",
    "        translates,\n",
    "        scales,\n",
    "    )\n",
    "]\n",
    "\n",
    "transforms = [\n",
    "    torch.nn.Sequential(\n",
    "        HorizontalFlip(flip=param[\"horizontal_flip\"]),\n",
    "        VerticalFlip(flip=param[\"vertical_flips\"]),\n",
    "        Affine(degrees=param[\"rotate_degree\"], translate=param[\"translate\"], scale=param[\"scale\"]),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    )\n",
    "    for param in params\n",
    "]\n",
    "\n",
    "batch_size = 32 * 6\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(y_hats.shape)\n",
    "print(target.shape)\n",
    "# ~20:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_log_dir: Path, tta_transforms: dict = None):\n",
    "    checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "    model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "    # disable randomness, dropout, etc...\n",
    "    model.eval()\n",
    "\n",
    "    if tta_transforms is not None:\n",
    "        model.tta_transforms = FetalLitModule.create_transforms(tta_transforms)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tta_transforms = {\n",
    "    \"horizontal_flips\": [False, True],\n",
    "    \"vertical_flips\": [False, True],\n",
    "    \"rotate_degrees\": [0, -5, 5],\n",
    "    \"translates\": [[0.0, 0.0]],\n",
    "    \"scales\": [1.0, 1.10],\n",
    "}\n",
    "\n",
    "models = [\n",
    "    load_model(model_log_dir, tta_transforms)\n",
    "    for model_log_dir in [\n",
    "        # seed 5724\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_22-41-24\",  # civilized-droid-3054\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-05_09-31-12\",  # carbonite-ewok-3069\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-04_14-12-45\",  # tusken-transport-3040\n",
    "        # seed 8910,\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-19_00-12-17\",  # dainty-totem-3234\n",
    "        # seed 9759\n",
    "        root / \"logs\" / \"train\" / \"runs\" / \"2025-05-19_11-58-46\",  # lunar-grass-3253\n",
    "    ]\n",
    "]\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodel_evaluate():\n",
    "    epochs = ceil(len(test) / batch_size)\n",
    "\n",
    "    y_hat_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    for batch in tqdm(test_data_loader, desc=\"Evaluate\"):\n",
    "        x, y = batch\n",
    "\n",
    "        y_hat_batch = []\n",
    "        for model in models:\n",
    "            x = x.to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, y_hat = model.forward_tta(x)\n",
    "\n",
    "            y_hat_batch.append(y_hat.cpu())\n",
    "\n",
    "        y_hat_batch = torch.stack(y_hat_batch, dim=1)\n",
    "        y_hat_batches.append(y_hat_batch)\n",
    "        y_batches.append(y)\n",
    "\n",
    "    return torch.cat(y_hat_batches, dim=0), torch.cat(y_batches, dim=0)\n",
    "\n",
    "\n",
    "test = FetalBrainPlanesDataset(\n",
    "    data_dir=data_dir,\n",
    "    subset=\"test\",\n",
    "    transform=torch.nn.Sequential(\n",
    "        T.Grayscale(),\n",
    "        T.Resize((165, 240), antialias=False),\n",
    "        T.ConvertImageDtype(torch.float32),\n",
    "    ),\n",
    "    target_transform=LabelEncoder(labels=label_names),\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "y_hats, target = multimodel_evaluate()\n",
    "print(y_hats.shape)\n",
    "print(target.shape)\n",
    "\n",
    "# 0 - 4:20\n",
    "# 8 - 4min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    # y_hat = torch.mean(y_hats, dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return acc(pred, target).item()\n",
    "\n",
    "\n",
    "print(accuracy(y_hats, target))  # 0.8330667018890381, 0.834805965423584\n",
    "print(accuracy(y_hats[:, [0]], target))\n",
    "# print(accuracy(y_hats[:, [0,1,2]], target))\n",
    "# print(accuracy(y_hats[:, [0,3,4]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    y_hat = torch.mean(y_hats, dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    prec = Precision(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return prec(pred, target).item()\n",
    "\n",
    "\n",
    "print(precision(y_hats, target))  # 0.7358236312866211, 0.7428303956985474\n",
    "print(precision(y_hats[:, [0]], target))\n",
    "# print(precision(y_hats[:, [0,1,2]], target))\n",
    "# print(precision(y_hats[:, [0,3,4]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    # y_hat = torch.mean(y_hats, dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    rec = Recall(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return rec(pred, target).item()\n",
    "\n",
    "\n",
    "print(recall(y_hats, target))  #\n",
    "print(recall(y_hats[:, [0]], target))\n",
    "# print(recall(y_hats[:, [0,1,2]], target))\n",
    "# print(recall(y_hats[:, [0,3,4]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1Score(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    # y_hat = torch.mean(y_hats, dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=len(label_names), average=\"macro\")\n",
    "    return f1(pred, target).item()\n",
    "\n",
    "\n",
    "print(f1Score(y_hats, target))  # 0.7551986575126648, 0.766685962677002\n",
    "print(f1Score(y_hats[:, [0]], target))\n",
    "# print(f1Score(y_hats[:, [0,1,2]], target))\n",
    "# print(f1Score(y_hats[:, [0,3,4]], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_stats(y_hats, target):\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    prec = Precision(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    rec = Recall(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=len(label_names), average=\"none\")\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc(pred, target).cpu().numpy(),\n",
    "        \"Precision\": prec(pred, target).cpu().numpy(),\n",
    "        \"Recall\": rec(pred, target).cpu().numpy(),\n",
    "        \"F1-score\": f1(pred, target).cpu().numpy(),\n",
    "    }\n",
    "\n",
    "\n",
    "with pd.option_context(\"display.float_format\", \"{:0.3f}\".format):\n",
    "    print(pd.DataFrame(all_stats(y_hats, target), index=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def confusion_matrix(y_hats, target):\n",
    "    if y_hats.size(1) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    y_hat = torch.mean(F.softmax(y_hats, dim=2), dim=1)\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(label_names))\n",
    "    cm_norm = ConfusionMatrix(task=\"multiclass\", num_classes=len(label_names), normalize=\"true\")\n",
    "\n",
    "    return cm(pred, target).cpu().numpy(), cm_norm(pred, target).cpu().numpy()\n",
    "\n",
    "\n",
    "cm, cm_norm = confusion_matrix(y_hats, target)\n",
    "\n",
    "cm_txt = []\n",
    "for row, row_norm in zip(cm, cm_norm):\n",
    "    row_txt = []\n",
    "    for cell, cell_norm in zip(row, row_norm):\n",
    "        txt = \"{quantity}\\n{perc:.2f}%\".format(quantity=cell, perc=cell_norm * 100)\n",
    "        row_txt.append(txt)\n",
    "    cm_txt.append(row_txt)\n",
    "cm_txt = np.array(cm_txt)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "fx = sns.heatmap(\n",
    "    cm_norm,\n",
    "    # format 0-1 probability\n",
    "    # annot=True,\n",
    "    # fmt=\".3f\",\n",
    "    # format - number of classes\n",
    "    annot=cm,\n",
    "    fmt=\".0f\",\n",
    "    # format - number of classes + % probability\n",
    "    # annot=cm_txt,\n",
    "    # fmt=\"\",\n",
    "    square=True,\n",
    "    cmap=sns.dark_palette(\"#69d\", as_cmap=True),\n",
    "    cbar=False,\n",
    "    xticklabels=label_names,\n",
    "    # yticklabels=label_names,\n",
    "    yticklabels=[\"Trans\\nventricular\", \"Trans\\nthalamic\", \"Trans\\ncerebellum\", \"Other\", \"Not A Brain\"],\n",
    "    annot_kws={\"size\": 12},\n",
    ")\n",
    "\n",
    "# labels the title and x, y axis of plot\n",
    "# fx.set_title(\"Plotting Confusion Matrix using Seaborn\\n\\n\")\n",
    "fx.set_xlabel(\"Predicted Labels\", size=16)\n",
    "fx.set_ylabel(\"True Labels\", size=16)\n",
    "\n",
    "fx.set_xticklabels(fx.get_xticklabels(), rotation=30, fontsize=12)\n",
    "fx.set_yticklabels(fx.get_yticklabels(), rotation=0, fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"plots/confusion_matrix.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-11-10_08-36-16\" / \"0\"  # graceful-plasma-2705\n",
    "\n",
    "checkpoint = sorted(model_log_dir.glob(\"checkpoints/epoch_*.ckpt\"))[-1]\n",
    "model = FetalLitModule.load_from_checkpoint(str(checkpoint))\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "y_hats, target = evaluate()\n",
    "\n",
    "print(accuracy(y_hats, target))\n",
    "print(accuracy(y_hats[:, [0]], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_score = pd.DataFrame(params)\n",
    "individual_score[\"accuracy\"] = [accuracy(y_hats[:, [i]], target) for i in range(y_hats.size(1))]\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):  # more options can be specified also\n",
    "    print(individual_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(left, n):\n",
    "    if n == 1:\n",
    "        return [[v] for v in left]\n",
    "\n",
    "    rs = gen(left, n - 1)\n",
    "\n",
    "    rrs = []\n",
    "    for v in left:\n",
    "        for r in rs:\n",
    "            rrs.append(r + [v])\n",
    "    return rrs\n",
    "\n",
    "\n",
    "def cumulative_accuracy(row):\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        add = True\n",
    "        for key, value in params[0].items():\n",
    "            if row[key] == \"-\" and param[key] != value:\n",
    "                add = False\n",
    "\n",
    "        if add:\n",
    "            idxs.append(i)\n",
    "\n",
    "    return accuracy(y_hats[:, idxs], target)\n",
    "\n",
    "\n",
    "cumulative_score = pd.DataFrame(gen([\"-\", \"+\"], 5), columns=params[0].keys())\n",
    "cumulative_score[\"accuracy\"] = [cumulative_accuracy(cumulative_score.loc[i]) for i in range(len(cumulative_score))]\n",
    "cumulative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    idxs = []\n",
    "    for i, param in enumerate(params):\n",
    "        for agr_param in aggregate_params:\n",
    "            if param == agr_param:\n",
    "                idxs.append(i)\n",
    "\n",
    "    return (\n",
    "        accuracy(y_hats[:, idxs], target),\n",
    "        precision(y_hats[:, idxs], target),\n",
    "        recall(y_hats[:, idxs], target),\n",
    "        f1Score(y_hats[:, idxs], target),\n",
    "    )\n",
    "\n",
    "\n",
    "aggregate_score(\n",
    "    # horizontal_flips=[False],\n",
    "    horizontal_flips=[False, True],\n",
    "    # vertical_flips=[False],\n",
    "    vertical_flips=[False, True],\n",
    "    # rotate_degrees=[0],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    # rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    # rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    translates=[(0.0, 0.0)],\n",
    "    # translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    # translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    # scales=[1.0],\n",
    "    scales=[1.0, 1.10],\n",
    "    # scales=[1.0, 1.05],\n",
    "    # scales=[1.0, 1.05, 1.10],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, 5],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_score(\n",
    "    horizontal_flips=[False, True],\n",
    "    vertical_flips=[False, True],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    return [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "scores = search_aggregate_score(\n",
    "    horizontal_flips=[[False], [False, True]],\n",
    "    vertical_flips=[[False], [False, True]],\n",
    "    rotate_degrees=[[0], [0, -5, 5], [0, -5, -10, 5, 10]],  # [0, -5, -10, -15, 5, 10, 15]\n",
    "    translates=[[(0.0, 0.0)], [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]],\n",
    "    scales=[[1.0], [1.0, 1.05, 1.10], [1.0, 1.05, 1.10, 1.15, 1.20]],\n",
    ")\n",
    "\n",
    "print(\"Best score\")\n",
    "pprint(max(scores, key=lambda x: x[\"score\"][3]))\n",
    "print(\"\")\n",
    "# sorted(scores, key=lambda x: x[\"score\"][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed_search_aggregate_score(horizontal_flips, vertical_flips, rotate_degrees, translates, scales):\n",
    "    horizontal_flips = perm(horizontal_flips)\n",
    "    vertical_flips = perm(vertical_flips)\n",
    "    rotate_degrees = perm(rotate_degrees)\n",
    "    translates = perm(translates)\n",
    "    scales = perm(scales)\n",
    "\n",
    "    aggregate_params = [\n",
    "        {\n",
    "            \"score\": aggregate_score(horizontal_flip, vertical_flips, rotate_degree, translate, scale),\n",
    "            \"horizontal_flip\": horizontal_flip,\n",
    "            \"vertical_flips\": vertical_flips,\n",
    "            \"rotate_degree\": rotate_degree,\n",
    "            \"translate\": translate,\n",
    "            \"scale\": scale,\n",
    "        }\n",
    "        for horizontal_flip, vertical_flips, rotate_degree, translate, scale in itertools.product(\n",
    "            horizontal_flips,\n",
    "            vertical_flips,\n",
    "            rotate_degrees,\n",
    "            translates,\n",
    "            scales,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return max(aggregate_params, key=lambda x: x[\"score\"][0])\n",
    "\n",
    "\n",
    "def perm(values):\n",
    "    list_of_lists = [list(itertools.combinations(values, i + 1)) for i in range(len(values))]\n",
    "    return list(itertools.chain(*list_of_lists))\n",
    "\n",
    "\n",
    "greed_search_aggregate_score(\n",
    "    # horizontal_flips=[False],\n",
    "    horizontal_flips=[False, True],\n",
    "    # vertical_flips=[False],\n",
    "    vertical_flips=[False, True],\n",
    "    # rotate_degrees=[0],\n",
    "    # rotate_degrees=[0, -5, 5],\n",
    "    rotate_degrees=[0, -5, -10, 5, 10],\n",
    "    # rotate_degrees=[0, -5, -10, -15, 5, 10, 15],\n",
    "    # translates=[(0.0, 0.0)],\n",
    "    translates=[(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)],\n",
    "    # translates=list(itertools.product([0.0, 0.1, -0.1], [0.0, 0.1, -0.1])),\n",
    "    # scales=[1.0],\n",
    "    # scales=[1.0, 1.05],\n",
    "    # scales=[1.0, 1.05, 1.10],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15],\n",
    "    scales=[1.0, 1.05, 1.10, 1.15, 1.20],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25],\n",
    "    # scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neat-aardvark-2941\n",
    "# fine-lion-2828\n",
    "# fresh-grass-2813\n",
    "# prime-butterfly-2873\n",
    "# lilac-frost-2893\n",
    "\n",
    "horizontal_flips = [False]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0]\n",
    "translates = [(0.0, 0.0)]\n",
    "scales = [1.0]\n",
    "# 0.7860984802246094 0.7706203460693359\n",
    "# 0.7940822243690491 0.7465180754661560\n",
    "# 0.7963624000549316 0.7576579451560974\n",
    "# 0.8050662279129028 0.7383250594139099\n",
    "# 0.7890244722366333 0.7428253293037415\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, 5]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10]\n",
    "# 0.7951812148094177 0.7918230891227720\n",
    "# 0.8120790719985962 0.7782592773437500\n",
    "# 0.7909176945686340 0.7713555693626404\n",
    "# 0.7989473342895508 0.7635297179222107\n",
    "# 0.7967666387557983 0.7601540088653564\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, 5]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7991837859153748 0.7918857336044310\n",
    "# 0.8086183667182922 0.7752655148506165\n",
    "# 0.7911577224731445 0.7767201662063599\n",
    "# 0.8024842739105225 0.7718890905380249\n",
    "# 0.8025256395339966 0.7683259844779968\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10]\n",
    "# 0.7910797595977783 0.7876892685890198\n",
    "# 0.8088076710700989 0.7740747332572937\n",
    "# 0.7852406501770020 0.7671951055526733\n",
    "# 0.8035995960235596 0.7657317519187927\n",
    "# 0.7966942787170410 0.7604588270187378\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False, True]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.7969303131103516 0.7968350648880005\n",
    "# 0.8065788745880127 0.7735700011253350\n",
    "# 0.7919420599937439 0.7783745527267456\n",
    "# 0.8007959127426147 0.7693001031875610\n",
    "# 0.8012878894805908 0.7667553424835205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playful-haze-2111\n",
    "# mix_ra\n",
    "# model_log_dir = root / \"logs\" / \"train\" / \"multiruns\" / \"2023-04-22_14-32-35\" / \"4\"\n",
    "\n",
    "horizontal_flips = [False, True]\n",
    "vertical_flips = [False]\n",
    "rotate_degrees = [0, -5, -10, 5, 10]\n",
    "translates = [(0.0, 0.0), (0.1, 0.1), (-0.1, 0.1), (-0.1, -0.1), (0.1, -0.1)]\n",
    "scales = [1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "\n",
    "# 0.7875436544418335\n",
    "# 0.8037662506103516\n",
    "# 0.821164608001709\n",
    "\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10]\n",
    "# 0.8078333735466003\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15]\n",
    "# 0.8159346580505371\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20]\n",
    "# 0.821164608001709\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25]\n",
    "#\n",
    "\n",
    "# scales=[1.0, 1.05, 1.10, 1.15, 1.20, 1.25, 1.30]\n",
    "# 0.8252905011177063"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
